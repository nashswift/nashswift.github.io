<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>周志华《机器学习》（AKA：西瓜书）笔记整理-第七章-贝叶斯分类器</title>
      <link href="/2023/06/10/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%B8%83%E7%AB%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/"/>
      <url>/2023/06/10/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%B8%83%E7%AB%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="7-1-贝叶斯决策论"><a href="#7-1-贝叶斯决策论" class="headerlink" title="7.1 贝叶斯决策论"></a>7.1 贝叶斯决策论</h1><p><strong>贝叶斯决策论（Bayesian decision theory）</strong>：是在概率框架下实施决策的基本方法。对于分类任务而言，在所有相关概率已知的理想条件下，贝叶斯决策论考虑如何基于这些概率和误判损失来选择最优类别标记。</p><p><strong>最小化分类错误率的贝叶斯最优分类器</strong>：<script type="math/tex">h^*(x)=\underset{c}{\arg\max}\ P(c|x)</script></p><blockquote><p><strong>判别式模型和生成式模型</strong>：</p><ul><li>判别式模型：通过直接建模<script type="math/tex">P(c|x)</script>来预测c，这样得到的是判别式模型。如决策树、BP神经网络、SVM等等。</li><li>生成式模型：先对概率分布<script type="math/tex">P(x,c)</script>进行建模，再利用贝叶斯定理<script type="math/tex">P(c|x)=\frac{P(c)P(x|c)}{P(x)}</script>来获得<script type="math/tex">P(c|x)</script>，这样得到的是生成式模型，其中<script type="math/tex">P(c)</script>是先验概率（prior），<script type="math/tex">P(x|c)</script>是条件概率（conditional probability）/似然（likelihood），<script type="math/tex">P(x)</script>是证据（evidence）因子。</li></ul></blockquote><h1 id="7-2-极大似然估计（频率学派）"><a href="#7-2-极大似然估计（频率学派）" class="headerlink" title="7.2 极大似然估计（频率学派）"></a>7.2 极大似然估计（频率学派）</h1><p>假定类条件概率<script type="math/tex">P(x|c)</script>被参数向量<script type="math/tex">\theta_c</script>唯一确定，我们的任务就是利用训练集D中第c类样本组成的集合<script type="math/tex">D_c</script>来估计参数向量<script type="math/tex">\theta_c</script>，而概率模型的训练过程就是<strong>参数估计（parameter estimation）</strong>过程。</p><blockquote><p><strong>频率学派和贝叶斯学派</strong>：</p><ul><li>频率学派：认为参数虽然未知，但是个客观存在的固定值，因此可以通过优化似然函数等方式来确定参数值。</li><li>贝叶斯学派：认为参数是未观察的随机变量，本身也有分布，因此可以假定参数副层一个先验分布，然后通过观测数据计算参数的后验分布。</li></ul></blockquote><p><strong>极大似然估计（maximum likelihood estimation，简称MLE）</strong>的求解过程：参数向量<script type="math/tex">\theta_c</script>对训练集D中第c类样本组成的集合<script type="math/tex">D_c</script>的<strong>对数似然</strong>为</p><script type="math/tex; mode=display">LL(\theta)=\log P(D_c|\theta_c)=\log\prod_{x\in D_c}P(x|D_c)=\sum_{x\in D_c}\log P(x|D_c)</script><blockquote><p>使用对数似然的目的：使得求导更简便，同时也防止连乘操作带来的下溢风险。</p></blockquote><p>此时参数的极大似然估计<script type="math/tex">\hat{\theta_c}</script>为：</p><script type="math/tex; mode=display">\hat{\theta_c}=\underset{\theta_c}{\arg\max}LL(\theta_c)</script><p>注意，这种参数化的方法虽然能使得类条件概率估计变得相对简单，但是<strong>估计结果的准确性严重依赖于所假设的概率分布形式是否符合潜在的真实数据分布</strong>，因此在实际应用中往往需要在一定程度上利用关于应用任务本身的经验知识。此外，由于类条件概率<script type="math/tex">P(x|c)</script>是在所有属性上的联合概率，因此难以从有限的训练样本中直接估计获得。</p><h1 id="7-3-朴素贝叶斯分类器"><a href="#7-3-朴素贝叶斯分类器" class="headerlink" title="7.3 朴素贝叶斯分类器"></a>7.3 朴素贝叶斯分类器</h1><p><strong>朴素贝叶斯分类器（naive Bayes classifier）</strong>：采用了<strong>“属性条件独立性假设”（attribute conditional independence assumption）</strong>——假设每个属性独立地对分类结果发生影响。</p><p>基于条件独立性（iid）假设，贝叶斯定理可以重写为</p><script type="math/tex; mode=display">P(c|x)=\frac{P(c)P(x|c)}{P(x)}=\frac{P(c)}{P(x)}\prod_{i=1}^{d}P(x_i|c)</script><p>朴素贝叶斯分类器的表达式为</p><script type="math/tex; mode=display">h_{nb}(x)=\underset{c}{\arg\max}\ P(c)\prod_{i=1}^dP(x_i|c)</script><p>令<script type="math/tex">D_c</script>表示训练集D中第c类样本组成的集合，<script type="math/tex">D_{c,x_i}</script>表示<script type="math/tex">D_c</script>在第i个属性上取值为<script type="math/tex">x_i</script>的样本组成的集合，则类先验概率为<script type="math/tex">P(c)=\frac{\lvert D_c\rvert}{\lvert D\rvert}</script>，条件概率为<script type="math/tex">P(x_i|c)=\frac{\lvert D_{c,x_i}\rvert}{\lvert D_c\rvert}</script>。</p><p>需要注意的是，若某个属性值在训练集D中没有与某个类出现过，上式将出现始终为0的情况。为了避免其他属性携带的信息被训练集中未出现的属性值“抹去”，在估计概率值时通常要采用<strong>“平滑”（smoothing）</strong>，常用<strong>“拉普拉斯修正”（Laplacian correction）</strong>。令N表示训练集D中的可能类别数，<script type="math/tex">N_i</script>表示第i个属性的可能取值数，先验概率和条件概率分别修正为</p><script type="math/tex; mode=display">\hat{P}(c)=\frac{\lvert D_c\rvert+1}{\lvert D\rvert+N}</script><script type="math/tex; mode=display">\hat{P}(x_i|c)=\frac{\lvert D_{c,x_i}\rvert+1}{\lvert D_c\rvert+N_i}</script><blockquote><p>现实中朴素贝叶斯分类器的多种使用方式：</p><ul><li>若任务对预测速度要求高：可将NB涉及的所有概率估值事先储存，预测时只需“查表”即可</li><li>若任务数据更替频繁：采用“懒惰学习”（lazy learning）方式</li><li>若数据不断增加：可在现有估值基础上仅对新增样本属性值所设计的概率估值进行修正即可</li></ul></blockquote><h1 id="7-4-半朴素贝叶斯分类器"><a href="#7-4-半朴素贝叶斯分类器" class="headerlink" title="7.4 半朴素贝叶斯分类器"></a>7.4 半朴素贝叶斯分类器</h1><p>由于朴素贝叶斯分类器所依赖的属性条件独立性假设在现实任务中往往很难成立，因此我们尝试对这一假设进行<strong>一定程度的放松</strong>，于是就得到了<strong>半朴素贝叶斯分类器（semi-naive Bayes classifiers）</strong>。</p><p><strong>独依赖估计（One-Dependent Estimator，简称ODE）</strong>：是半朴素贝叶斯分类器最常用的策略。假设每个属性在类别之外<strong>最多仅依赖于一个其他属性</strong>，即</p><script type="math/tex; mode=display">P(c|x)\propto P(c)\prod_{i=1}^dP(x_i|c,pa_i)</script><p>其中<script type="math/tex">pa_i</script>为属性<script type="math/tex">x_i</script>所依赖的属性，称为<script type="math/tex">x_i</script>的父属性。</p><p><strong>how确定每个属性的父属性？</strong></p><ul><li><strong>SPODE（Super-Parent ODE）方法</strong>：假设所有属性都依赖于同一个属性——<strong>“超父”（super-parent）</strong>，然后通过交叉验证等方法确定超父属性。</li><li><strong>TAN（Tree Augmented naive Bayes）方法</strong>：在最大带权生成树（maximum weighted spanning tree）算法的基础上，将属性之间的强依赖关系约简为<strong>树形结构</strong>，TAN实际上只保留了强相关属性之间的依赖性。</li><li><strong>AODE（Averaged One-Dependent Estimator）方法</strong>：尝试将每个属性都作为超父来构建SPODE，然后将那些有足够训练数据支撑的SPODE<strong>集成</strong>起来作为最终结果。</li></ul><p><img src="/2023/06/10/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%B8%83%E7%AB%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/半朴素贝叶斯分类器.png" alt="半朴素贝叶斯分类器"></p><blockquote><p>也可以考虑<strong>高阶依赖</strong>来进一步提升泛化性能，从而将ODE拓展为kDE，但由此带来的所需训练样本的数量将以指数级增加，同时也容易陷入估计高阶联合概率的泥沼。</p></blockquote><h1 id="7-5-贝叶斯网"><a href="#7-5-贝叶斯网" class="headerlink" title="7.5 贝叶斯网"></a>7.5 贝叶斯网</h1><p><strong>贝叶斯网（Bayesian network）/信念网（belief network）</strong>：借助有向无环图（Directed Acyclic Graph，简称DAG）来刻画属性之间的依赖关系，并使用条件概率表（Conditional Probability，简称CPT）描述属性的联合概率分布。一个贝叶斯网B由结构G和参数<script type="math/tex">\Theta</script>两部分构成，即<script type="math/tex">G=\langle G,\Theta\rangle</script>，其中网络结构G是一个DAG，每个节点对应一个属性，每条边对应两个节点（属性）的直接依赖关系；参数<script type="math/tex">\Theta</script>用于定量描述这种依赖关系。</p><p><img src="/2023/06/10/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%B8%83%E7%AB%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/贝叶斯网和条件概率表.png" alt="贝叶斯网和条件概率表"></p><h2 id="7-5-1-结构"><a href="#7-5-1-结构" class="headerlink" title="7.5.1 结构"></a>7.5.1 结构</h2><p><strong>贝叶斯网中的联合概率分布：</strong>给定属性<script type="math/tex">x_i</script>在贝叶斯网G中的父节点集<script type="math/tex">\pi_i</script>，贝叶斯网假设每个属性与它的非后裔属性独立（无环），因此贝叶斯网<script type="math/tex">G=\langle G,\Theta\rangle</script>将属性<script type="math/tex">x_1,x_2,...,x_d</script>的联合概率分布定义为</p><script type="math/tex; mode=display">P_B(x_1,x_2,...,x_d)=\prod_{i=1}^d{P_B(x_i|\pi_i)}=\prod_{i=1}^d\theta_{x_i|\pi_i}</script><p><strong>贝叶斯网络中的三种典型结构</strong>：</p><ul><li><strong>同父（common parent）结构/tail-to-tail结构</strong>：给定父节点<script type="math/tex">x_1</script>的取值，则<script type="math/tex">x_3</script>与<script type="math/tex">x_4</script>条件独立</li><li><strong>V型结构（V-structure）结构/冲撞结构/head-to-head结构</strong>：给定子节点<script type="math/tex">x_4</script>的取值，则<script type="math/tex">x_1</script>与<script type="math/tex">x_2</script>必定不独立；若<script type="math/tex">x_4</script>的取值完全未知，则<script type="math/tex">x_1</script>与<script type="math/tex">x_2</script>条件独立，称之为边界独立性（marginal independence）</li><li><strong>顺序结构/head-to-tail结构</strong>：给定x的取值，则y与z条件独立</li></ul><p><img src="/2023/06/10/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%B8%83%E7%AB%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/贝叶斯网中的三种依赖关系.png" alt="贝叶斯网中的三种依赖关系"></p><h2 id="7-5-2-学习"><a href="#7-5-2-学习" class="headerlink" title="7.5.2 学习"></a>7.5.2 学习</h2><p><strong>评分函数（score function）</strong>：用来评估贝叶斯网与训练数据的契合程度，然后基于这个评分函数来寻找结构最优的贝叶斯网，常用的评分函数通常基于信息论准则。</p><p><strong>最小描述长度（Minimal Description Length，简称MDL）准则</strong>：我们应选择那个综合编码长度（包括描述网络和编码数据）最短的贝叶斯网。</p><p>设<script type="math/tex">f(\theta)</script>表示描述每个参数<script type="math/tex">\theta</script>所需的编码位数，则贝叶斯网<script type="math/tex">G=\langle G,\Theta\rangle</script>在训练集D上的评分函数为</p><script type="math/tex; mode=display">s(B|D)=f(\theta)\lvert B\rvert-LL(B|D)=f(\theta)\lvert B\rvert-\sum_{i=1}^m\log P_B(x_i)</script><p>其中第一项是计算编码贝叶斯网B所需的编码位数，第二项是计算B对应的概率分布<script type="math/tex">P_B</script>对D描述得多好。为了最小化评分函数<script type="math/tex">s(B|D)</script>，只需对网格结构进行搜索，而候选结构的最优参数可以直接在训练集上通过经验估计获得，即<script type="math/tex">\theta_{x_i|\pi_i}=\hat{P}_D(x_i|\pi_i)</script>。</p><ul><li>若<script type="math/tex">f(\theta)=1</script>，则得到<strong>AIC（Akaike Information Criterion）评分函数</strong>：</li></ul><script type="math/tex; mode=display">AIC(B|D)=\lvert B\rvert-LL(B|D)</script><ul><li>若<script type="math/tex">f(\theta)=\frac{1}{2}\log m</script>，则得到<strong>BIC（Bayesian Information Criterion）评分函数</strong>：</li></ul><script type="math/tex; mode=display">BIC(B|D)=\frac{\log m}{2}\lvert B\rvert-LL(B|D)</script><ul><li>若<script type="math/tex">f(\theta)=0</script>，则评分函数退化为<strong>对数似然</strong>。</li></ul><blockquote><p>从所有可能的网络空间搜索最优贝叶斯网络是一个<strong>NP难问题</strong>，常用策略有：</p><ol><li>贪心法，例如从某个网络结构出发每次调整一条边，直到评分函数值不再降低为止</li><li>通过给网络结构施加约束来削减搜索空间，例如限定网格结构为树形结构等</li></ol></blockquote><h2 id="7-5-3-推断"><a href="#7-5-3-推断" class="headerlink" title="7.5.3 推断"></a>7.5.3 推断</h2><p><strong>推断（inference）</strong>：通过已知变量（证据）来推测待查询变量的过程。</p><blockquote><p>精确推断：NP难</p><p>近似推断：通过降低精度要求，在有限时间内求得近似解</p></blockquote><p><strong>吉布斯采样（Gibbs sampling）</strong>：用作贝叶斯网的近似推断。</p><p><img src="/2023/06/10/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%B8%83%E7%AB%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/吉布斯采样算法.png" alt="吉布斯采样算法"></p><p><strong>吉布斯采样法的缺点</strong>：</p><ol><li>吉布斯采样算法的收敛速度较慢</li><li>若贝叶斯网中出现极端概率0/1，此时吉布斯采样算法会给出错误的估计结果</li></ol><h1 id="7-6-EM算法"><a href="#7-6-EM算法" class="headerlink" title="7.6 EM算法"></a>7.6 EM算法</h1><p><strong>隐变量（latent variable）</strong>：未观测变量。</p><p><strong>EM（Expectation-Maximization）算法</strong>：估计参数隐变量的方法，可以视作使用坐标下降（coordinate descent）法来最大化对数似然下界的过程。</p><ul><li><strong>E-step（Expectation）</strong>：根据当前估计的参数值来计算对数似然的期望值</li><li><strong>M-step（Maximization）</strong>：寻找E步产生似然期望最大化的参数值</li></ul><p>具体步骤（参考李航《统计学习方法》中对EM算法的描述）：</p><p>输入：观测变量数据集X，隐变量数据集Z，联合分布<script type="math/tex">P(X,Z|\theta)</script>，条件分布<script type="math/tex">P(Z|Y,\theta)</script></p><p>输出：模型参数<script type="math/tex">\theta</script></p><p>Step1：选择模型参数的初值<script type="math/tex">\theta^0</script>，开始迭代</p><p>Step2：（E-step）记<script type="math/tex">\theta^{(i)}</script>为第i次迭代时模型参数<script type="math/tex">\theta</script>的估计值，在第i+1次迭代的E步，计算</p><script type="math/tex; mode=display">Q(\theta,\theta^{(i)})=E_{Z|X,\theta^{(i)}}LL(\theta|X,Z)=\sum_Z\log P(X,Z|\theta)P(Z|X,\theta^{(i)})</script><p>Step3：（M-step）求使得<script type="math/tex">Q(\theta,\theta^{(i)})</script>最大化的模型参数<script type="math/tex">\theta</script>，以此确定第i+1次迭代的参数估计值<script type="math/tex">\theta^{(i+1)}</script></p><script type="math/tex; mode=display">\theta^{(i+1)}=\underset{\theta}{\arg\max}\ Q(\theta,\theta^{(i)})</script><p>Step4：重复第2步和第3步直到收敛</p>]]></content>
      
      
      <categories>
          
          <category> ML study </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>周志华《机器学习》（AKA：西瓜书）笔记整理-第六章-支持向量机</title>
      <link href="/2023/06/09/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E5%85%AD%E7%AB%A0-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"/>
      <url>/2023/06/09/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E5%85%AD%E7%AB%A0-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="6-1-间隔与支持向量"><a href="#6-1-间隔与支持向量" class="headerlink" title="6.1 间隔与支持向量"></a>6.1 间隔与支持向量</h1><p>分类学习的基本想法是基于训练集D找到一个划分超平面<script type="math/tex">w^Tx+b=0</script>将不同类的样本分开，而这种划分超平面往往有很多。因此我们更希望找到位于两类样本<strong>“正中间”</strong>的划分超平面，因为这个划分超平面所产生的分类结果是鲁棒的，对新样本的泛化能力最强。</p><p><img src="/2023/06/09/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E5%85%AD%E7%AB%A0-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/多个划分超平面.png" alt="多个划分超平面"></p><p>假定超平面<script type="math/tex">(w,b)</script>能将训练样本正确分类，对于训练集D中任意一个样本<script type="math/tex">(x_i,y_i)</script>，有：</p><script type="math/tex; mode=display">\begin{cases}w^Tx_i+b\geq+1,\quad y_i=+1\\w^Tx_i+b\leq-1,\quad y_i=-1\end{cases}</script><p><strong>支持向量（support vector）</strong>：使得上式等号成立的距离超平面最近的点。</p><p><strong>间隔（margin）</strong>：两个异类支持向量到超平面的距离之和<script type="math/tex">\gamma=\frac{2}{||w||}</script>。</p><p><strong>补充：函数间隔与几何间隔</strong></p><ul><li><strong>函数间隔（functional margin）</strong>：定义超平面<script type="math/tex">(w,b)</script>关于样本点<script type="math/tex">(x_i,y_i)</script>的函数间隔为<script type="math/tex">\hat{\gamma_i}=y_i(w^Tx_i+b)</script>，则超平面<script type="math/tex">(w,b)</script>关于训练集D的函数间隔为<script type="math/tex">\hat{\gamma}=\underset{i=1,...,N}{min}\hat{\gamma_i}</script>。</li></ul><blockquote><p>如果成比例地改变w和b，超平面没有改变，但函数间隔的值缺变成了原来的2倍。</p></blockquote><ul><li><strong>几何间隔（geometrical margin）</strong>：定义超平面<script type="math/tex">(w,b)</script>关于样本点<script type="math/tex">(x_i,y_i)</script>的几何间隔为<script type="math/tex">\gamma_i=y_i\big(\frac{w}{||w||}x_i+\frac{b}{||w||}\big)</script>，则超平面<script type="math/tex">(w,b)</script>关于训练集D的函数间隔为<script type="math/tex">\gamma=\underset{i=1,...,N}{min}{\gamma_i}</script>。</li></ul><blockquote><p>由上述定义可以看出函数间隔与几何间隔之间的关系是<script type="math/tex">\gamma=\frac{\hat{\gamma}}{||w||}</script>，若<script type="math/tex">||w||=1</script>，那么函数间隔与几何间隔相等。若w和b成比例改变（超平面不变），函数间隔也按此比例改变，几何间隔不变。</p></blockquote><p><img src="/2023/06/09/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E5%85%AD%E7%AB%A0-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/支持向量和间隔.png" alt="支持向量和间隔"></p><p><strong>支持向量机（support vector machines，简称SVM）</strong>：是一种二分类模型，目的是为了寻找一个“最优”的超平面来对样本进行分割，其基本模型定义为特征空间上间隔最大的线性分类器，分割的策略是<strong>间隔最大化</strong>（分类的确信度也最大），最终转换为一个凸优化问题求解。</p><p><strong>支持向量机的基本型</strong>：</p><script type="math/tex; mode=display">\begin{split}\underset{w,b}{min}\ \frac{1}{2}\lVert w\rVert^2\\s.t.\ y_i(w^Tx_i+b)\geq 1\\i=1,2,...,m\end{split}</script><h1 id="6-2-对偶问题"><a href="#6-2-对偶问题" class="headerlink" title="6.2 对偶问题"></a>6.2 对偶问题</h1><p>由支持向量机的基本型可知，现在的目标函数是二次的、约束条件是线性的，所以是一个<strong>凸二次规划问题（convex quadratic programming）</strong>，能用现成的QP（Quadratic Programming）优化包求解，也可以使用拉格朗日乘子法变换为<strong>对偶问题（dual problem）</strong>进行求解。</p><blockquote><p>给每个约束条件加上拉格朗日乘子（lagrange multiplier），并定义拉格朗日函数：</p><script type="math/tex; mode=display">L(w,b,\alpha)=\frac{1}{2}||w||^2+\sum_{i=1}^{m}\alpha_i(1-y_i(w^T+b))</script><p>原问题的解<script type="math/tex">p^*=\underset{w,b}{min}\ \underset{\alpha_i \geq 0}{max}\ L(w,b,\alpha)</script>，转换为对偶问题的解<script type="math/tex">d^*=\underset{\alpha_i \geq 0}{max}\ \underset{w,b}{min}\ L(w,b,\alpha)</script>，通常情况下<script type="math/tex">d^*\leq p^*</script>，如果满足<strong>强对偶（strong duality）</strong>条件，则两者相等，即可以通过对偶问题来间接地求解原始问题。</p></blockquote><p>转换后得到的<strong>对偶问题</strong>：</p><script type="math/tex; mode=display">\begin{split}\underset{\alpha}{\max}\ \sum_{i=1}^{m}\alpha_i-\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{m}\alpha_i\alpha_jy_iy_jx_i^Tx_j\\s.t.\ \sum_{i=1}^{m}\alpha_iy_i=0,\ \alpha_i\geq 0,\ i=1,2,...,m\end{split}</script><p>上述过程需要满足<strong>KKT（Karush-Kuhn-Tucker）条件</strong>：</p><script type="math/tex; mode=display">\begin{cases}\alpha_i \geq0;\\y_if(x_i)-1\geq 0;\\\alpha_i(y_if(x_i)-1)=0.\end{cases}</script><p>求解出<script type="math/tex">\alpha</script>后，求解出w和b后可得到模型</p><script type="math/tex; mode=display">f(x)=w^Tx+b=\sum_{i=1}^{m}\alpha_iy_ix_i^Tx+b</script><blockquote><p>可以采用SMO算法进行高效求解</p></blockquote><h1 id="6-3-核函数"><a href="#6-3-核函数" class="headerlink" title="6.3 核函数"></a>6.3 核函数</h1><p>先前讨论的SVM只能处理线性情况，即训练样本是线性可分的。事实上，大部分时候数据并不是线性可分的，对这样的非线性情况<strong>可将样本从原始空间映射到一个更高维的特征空间</strong>，使得样本在这个特征空间内线性可分。</p><p><strong>核函数（kernel function）</strong>：实现高维映射后的内积计算。</p><script type="math/tex; mode=display">\kappa(x_i,x_j)=\langle\phi(x_i),\phi(x_j)\rangle=\phi(x_i)^T\phi(x_j)</script><blockquote><p><strong>常用的核函数</strong>：</p><div class="table-container"><table><thead><tr><th style="text-align:center">名称</th><th style="text-align:center">表达式</th></tr></thead><tbody><tr><td style="text-align:center">线性核</td><td style="text-align:center"><script type="math/tex">\kappa(x_i,x_j)=x_i^Tx_j</script></td></tr><tr><td style="text-align:center">多项式核</td><td style="text-align:center"><script type="math/tex">\kappa(x_i,x_j)=(x_i^Tx_j)^d</script></td></tr><tr><td style="text-align:center">高斯核</td><td style="text-align:center"><script type="math/tex">\kappa(x_i,x_j)=\exp (-\frac{\lVert x_i-x_j\rVert^2}{2\sigma^2})</script></td></tr><tr><td style="text-align:center">拉普拉斯核</td><td style="text-align:center"><script type="math/tex">\kappa(x_i,x_j)=\exp (-\frac{\lVert x_i-x_j\rVert}{2\sigma})</script></td></tr><tr><td style="text-align:center">Sigmoid核</td><td style="text-align:center"><script type="math/tex">\kappa(x_i,x_j)=tanh(\beta x_i^Tx_j+\theta)</script></td></tr></tbody></table></div><p><strong>核函数的组合</strong>：</p><ul><li>若<script type="math/tex">\kappa_1</script>和<script type="math/tex">\kappa_2</script>为核函数，则对于任意正数a和b，其线性组合<script type="math/tex">a\kappa_1+b\kappa_2</script>也是核函数</li><li>若<script type="math/tex">\kappa_1</script>和<script type="math/tex">\kappa_2</script>为核函数，则核函数的直积<script type="math/tex">\kappa_1\otimes\kappa_2(x,z)=\kappa_1(x,z)\kappa_2(x,z)</script>也是核函数</li><li>若<script type="math/tex">\kappa_1</script>为核函数，则对于任意函数<script type="math/tex">g(x)</script>，<script type="math/tex">\kappa(x,z)=g(x)\kappa_1(x,z)g(z)</script>也是核函数</li></ul></blockquote><p>通过<strong>核技巧（kernel trick）</strong>，SVM对偶问题可以重写为</p><script type="math/tex; mode=display">\begin{split}\underset{\alpha}{\max}\ \sum_{i=1}^{m}\alpha_i-\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{m}\alpha_i\alpha_jy_iy_j\kappa(x_i,x_j)\\s.t.\ \sum_{i=1}^{m}\alpha_iy_i=0,\ \alpha_i\geq 0,\ i=1,2,...,m\end{split}</script><p>求解后得到的模型解形为</p><script type="math/tex; mode=display">f(x)=w^T\phi(x)+b=\sum_{i=1}^m{\alpha_iy_j\phi(x_i)^T\phi(x)}+b=\sum_{i=1}^m\alpha_iy_i\kappa(x,x_i)+b</script><p>由上式可知模型最优解可通过训练样本的核函数展开，这一展开式亦称为<strong>“支持向量展式”（support vector expansion）</strong>。</p><h1 id="6-4-软间隔与正则化"><a href="#6-4-软间隔与正则化" class="headerlink" title="6.4 软间隔与正则化"></a>6.4 软间隔与正则化</h1><p><strong>软间隔支持向量机（soft margin SVM）</strong>：允许支持向量机在一些样本上出错，即允许某些样本不满足约束<script type="math/tex">y_i(w^Tx_i+b)\geq 1</script>，且这些不满足约束的样本尽可能少。</p><p><img src="/2023/06/09/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E5%85%AD%E7%AB%A0-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/软间隔.png" alt="软间隔"></p><p>软间隔支持向量机<strong>优化目标</strong>可写为：</p><script type="math/tex; mode=display">\underset{w,b}{\min}\ \frac{1}{2}\lVert w\rVert^2+C\sum_{i=1}^m{l(y_i(w^Tx_i+b-1))}</script><blockquote><p><strong>常用的loss function损失函数有</strong>：</p><ul><li>0/1损失：</li></ul><script type="math/tex; mode=display">l_{0/1}(z)=\begin{cases}1,\quad if\ z<0;\\0,\quad otherwise\end{cases}</script><ul><li>hinge损失：<script type="math/tex">l_{hinge}(z)=\max(0,1-z)</script></li><li>指数损失（exponential loss）：<script type="math/tex">l_{exp}(z)=\exp(-z)</script></li><li>对率损失（logistic loss）：<script type="math/tex">l_{log}(z)=\log(1+\exp(-z))</script></li></ul><p><img src="/2023/06/09/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E5%85%AD%E7%AB%A0-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/损失函数.png" alt="损失函数"></p></blockquote><p>软间隔支持向量机优化目标<strong>更一般的形式（正则化问题）</strong>：</p><script type="math/tex; mode=display">\underset{f}{\min}\ \Omega(f)+C\sum_{i=1}^{m}l(f(x_i),y_i)</script><p>其中第一项<script type="math/tex">\Omega(f)</script>称为<strong>结构风险（structural risk）/正则化项</strong>，用来描述模型f的性质；第二项<script type="math/tex">\sum_{i=1}^{m}l(f(x_i),y_i)</script>称为<strong>经验风险（empirical risk）</strong>，用来描述模型与训练数据的契合程度；C称为<strong>正则化常数</strong>，对结构风险与经验风险进行折中。</p><h1 id="6-5-支持向量回归"><a href="#6-5-支持向量回归" class="headerlink" title="6.5 支持向量回归"></a>6.5 支持向量回归</h1><p><strong>支持向量回归（Support Vector Regression，简称SVR）</strong>：假设我们能容忍f(x)与y之间<strong>最多有<script type="math/tex">\epsilon</script>的偏差</strong>，即仅当f(x)与y之间的差别绝对值大于<script type="math/tex">\epsilon</script>时才计算损失。故SVR的<strong>原始优化目标</strong>为</p><script type="math/tex; mode=display">\underset{w,b}{\min}\ \frac{1}{2}\lVert w\rVert^2+C\sum_{i=1}^ml_\epsilon(f(x_i)-y_i)</script><p>其中<script type="math/tex">l_\epsilon</script>为<strong><script type="math/tex">\epsilon</script>-不敏感损失（<script type="math/tex">\epsilon</script>-insensitive loss）函数</strong>：</p><script type="math/tex; mode=display">l_\epsilon=\begin{cases}0,\quad if\lvert z\rvert\leq\epsilon;\\\lvert z\rvert-\epsilon,\quad otherwise\end{cases}</script><p><img src="/2023/06/09/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E5%85%AD%E7%AB%A0-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/SVR.png" alt="SVR"></p><p>引入松弛变量<script type="math/tex">\xi_i</script>和<script type="math/tex">\hat{\xi_i}</script>（间隔带两侧的松弛程度可能有所不同），<strong>原始优化目标</strong>重写为</p><script type="math/tex; mode=display">\begin{split}\underset{w,b,\xi_i,\hat{\xi_i}}{\min}\ \frac{1}{2}\lVert w\rVert^2+C\sum_{i=1}^m(\xi_i+\hat{\xi_i})\\s.t.\ f(x_i)-y_i\leq\epsilon+\xi_i,\\y_i-f(x_i)\leq\epsilon+\hat{\xi_i},\\\xi_i\geq0,\hat{\xi_i}\geq0,i=1,2,...,m\end{split}</script><p>转换为<strong>SVR对偶问题</strong>：</p><script type="math/tex; mode=display">\begin{split}\underset{\alpha,\hat{\alpha}}{\max}\ \sum_{i=1}^my_i(\hat{\alpha_i}-\alpha_i)-\epsilon(\hat{\alpha_i}+\alpha_i)-\frac{1}{2}\sum_{i=1}^m\sum_{j=1}^m(\hat{\alpha_i}-\alpha_i)(\hat{\alpha_j}-\alpha_j)x_i^Tx_j\\s.t.\ \sum_{i=1}^m(\hat{\alpha_i}-\alpha_i)=0,\ 0\leq\alpha_i,\hat{\alpha_i}\leq C\end{split}</script><p>上述过程需要满足<strong>KKT条件</strong>：</p><script type="math/tex; mode=display">\begin{cases}\alpha_i(f(x_i)-y_i-\epsilon-\xi_i)=0\\\hat{\alpha_i}(f(x_i)-y_i-\epsilon-\hat{\xi_i})=0\\\alpha_i\hat{\alpha_i}=0\\\xi_i\hat{\xi_i}=0\\(C-\alpha_i)\xi_i=0\\(C-\hat{\alpha_i})\hat{\xi_i}=0\end{cases}</script><p>求解后得到的模型解形为</p><script type="math/tex; mode=display">f(x)=\sum_{i=1}^m(\hat{\alpha_i}-\alpha_i)x_i^Tx+b</script><p>同样地，也可以对SVR问题采用核技巧，使得SVR能够解决非线性回归问题：</p><script type="math/tex; mode=display">f(x)=\sum_{i=1}^m(\hat{\alpha_i}-\alpha_i)\kappa(x,x_i)+b</script><p>其中<script type="math/tex">\kappa(x_i,x_j)=\phi(x_i)^T\phi(x_j)</script>为核函数。</p><h1 id="6-5-核方法"><a href="#6-5-核方法" class="headerlink" title="6.5 核方法"></a>6.5 核方法</h1><p><strong>表示定理（representer theorem）</strong>：对于一般的损失函数和正则化项，优化问题的最优解<script type="math/tex">y^*</script>均可以表示为核函数<script type="math/tex">\kappa(x,x_i)</script>的线性组合。</p><p><strong>核方法（kernel methods）</strong>：一系列基于核函数的学习方法，最常见的就是通过引入核函数将线性学习器拓展为非线性学习器。</p>]]></content>
      
      
      <categories>
          
          <category> ML study </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>周志华《机器学习》（AKA：西瓜书）笔记整理-第五章-神经网络</title>
      <link href="/2023/06/08/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2023/06/08/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="5-1-神经元模型"><a href="#5-1-神经元模型" class="headerlink" title="5.1 神经元模型"></a>5.1 神经元模型</h1><p><strong>神经网络（neural network）</strong>：是一个强大的机器学习方法，由具有适应性的简单单元——<strong>神经元（neuron）</strong>组成的广泛并行互连的网络，能够模拟生物神经系统对真实世界物体作出交互式反应，是<strong>深度学习（deep learning）</strong>的基础。</p><p><strong>M-P神经元模型</strong>：神经元接收到其他n个神经元传递进来的输入信号，这些输入信号通过带权重的连接（connection）进行传递，并将收到的总输入值与神经元阈值相比较，最后通过<strong>激活函数（active function）</strong>处理以产生神经元的输出。把许多这样的神经元按照一定的层次结构连接起来，就得到了神经网络。</p><p><img src="/2023/06/08/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/M-P神经元模型.png" alt="M-P神经元模型"></p><p><strong>激活函数（active function）</strong>：常见的激活函数有</p><ul><li><strong>单位阶跃函数</strong>：将输入值映射为0（神经元抑制），1（神经元兴奋）。但该函数具有<strong>不连续、不光滑</strong>等不好的性质，不便于后续求导。</li><li><strong>对率函数（logistic function）/挤压函数（squashing function）</strong>：是一种<strong>“Sigmoid”函数</strong>，将较大范围内变化的输入值挤压到(0,1)输出值范围内，且函数处处可导，因此更为常用。</li></ul><p><img src="/2023/06/08/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/典型的神经元激活函数.png" alt="典型的神经元激活函数"></p><h1 id="5-2-感知机与多层网络"><a href="#5-2-感知机与多层网络" class="headerlink" title="5.2 感知机与多层网络"></a>5.2 感知机与多层网络</h1><h2 id="5-2-1-感知机"><a href="#5-2-1-感知机" class="headerlink" title="5.2.1 感知机"></a>5.2.1 感知机</h2><p><strong>感知机（perceptron）</strong>：由两层神经元组成，输入层接受外界输入信号后传递给输出层，输出层是M-P神经元（也称为阈值逻辑单元）。注意到<script type="math/tex">y=f(\sum_iw_ix_i-\theta)</script>，将阈值<script type="math/tex">\theta</script>看作输入为-1的哑节点（dummy node），对应的连接权重为<script type="math/tex">w_{n+1}</script>，这样权重和阈值的学习就可以统一为权重的学习。</p><p><img src="/2023/06/08/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/感知机.png" alt="感知机"></p><p><strong>感知机的学习规则</strong>：利用梯度下降法进行调整</p><script type="math/tex; mode=display">\begin{split}w_i \leftarrow w_i+\Delta w_i\\\Delta w_i=\eta(y-\hat{y})x_i\end{split}</script><blockquote><p>感知机只有输出层神经元进行激活函数处理，即只有一层功能神经元（functional neuron），其学习能力非常有限，只能处理线性可分的为题，不能解决诸如异或问题这样的非线性可分问题。</p></blockquote><h2 id="5-2-2-多层功能神经元（多层网络）"><a href="#5-2-2-多层功能神经元（多层网络）" class="headerlink" title="5.2.2 多层功能神经元（多层网络）"></a>5.2.2 多层功能神经元（多层网络）</h2><p>对于线性不可分的问题（如异或问题等），则需要使用多层功能神经元。输出层与输入层之间的一层神经元，被称为<strong>隐层（hidden layer）</strong>，隐层和输出层神经元都是拥有激活函数的功能神经元。</p><p><strong>多层前馈神经网络（multi-layer feedforward neural networks）</strong>：每层神经元与下层神经元全互连，神经元之间不存在同层连接，也不存在跨层连接，前馈是指网络拓扑结构上不存在环或者回路。</p><ul><li>输出层：输出层神经元为功能神经元，进行函数处理。</li><li>隐层：隐层神经元为功能神经元，进行函数处理。</li><li>输入层：输入层神经元仅接收外界输入信息，不进行函数处理。</li></ul><p><img src="/2023/06/08/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/多层前馈神经网络.png" alt="多层前馈神经网络"></p><blockquote><p>神经网络的学习过程，就是根据训练数据来调整神经元之间的连接权重和神经元阈值。换言之，神经网络“学习”到的东西，蕴含在连接权重和阈值中。</p></blockquote><h1 id="5-3-误差逆传播算法（BP算法）——对梯度计算结果的解释"><a href="#5-3-误差逆传播算法（BP算法）——对梯度计算结果的解释" class="headerlink" title="5.3 误差逆传播算法（BP算法）——对梯度计算结果的解释"></a>5.3 误差逆传播算法（BP算法）——对梯度计算结果的解释</h1><h2 id="5-3-1-标准BP算法"><a href="#5-3-1-标准BP算法" class="headerlink" title="5.3.1 标准BP算法"></a>5.3.1 标准BP算法</h2><p><strong>误差逆传播（error BackPropagation，简称BP）算法</strong>：给定训练集<script type="math/tex">D=\{ (x_1,y_1),...,(x_m,y_m)\},x_i\in\Re^d,y_i\in\Re^l</script>，即输入样本有d个属性，输入向量为l维。假定多层前馈神经网络拥有d个输入神经元，l个输出神经元，q个隐层神经元，其中具体参数有：</p><ul><li><script type="math/tex">\theta_j</script>：输出层第j个神经元的阈值</li><li><script type="math/tex">\gamma_h</script>：隐层第h个神经元的阈值</li><li><script type="math/tex">\upsilon_{ih}</script>：输入层第i个神经元与隐层第h个神经元之间的连接权重</li><li><script type="math/tex">\omega_{hj}</script>：隐层第h个神经元与输出层第j个神经元之间的连接权重</li><li><script type="math/tex">x_i</script>：输入层第i个神经元的输入</li><li><script type="math/tex">y_j</script>：输出层第j个神经元的输出</li><li><script type="math/tex">\alpha_h</script>；隐层第h个神经元的输入</li><li><script type="math/tex">b_h</script>：隐层第h个神经元的输出</li><li><script type="math/tex">\beta_j</script>：输出层第j个神经元的输入</li></ul><p>假设功能神经元激活函数都为对率函数<script type="math/tex">y=\frac{1}{1+e^{-x}}</script>。该多层前馈神经网络中总共有(d+1+l)*q+l个参数需要确定，BP是一个迭代学习算法，在迭代的每一轮都采用广义感知机学习规则（基于梯度下降策略寻找最小化均方误差，以目标的负梯度方向对参数进行调整）对参数进行更新估计，因此对于任意一个参数v，更新公式为<script type="math/tex">v \leftarrow v+\Delta v</script>。</p><p><img src="/2023/06/08/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/BP网络.png" alt="BP网络"></p><p>BP算法中的更新公式：</p><script type="math/tex; mode=display">\Delta w_{hj}=\eta g_jb_h</script><script type="math/tex; mode=display">\Delta \theta_j=-\eta g_j</script><script type="math/tex; mode=display">\Delta \upsilon_{ih}=\eta e_hx_i</script><script type="math/tex; mode=display">\Delta \gamma_h=-\eta e_h</script><p>其中，<script type="math/tex">g_i</script>为输出层神经元梯度项，<script type="math/tex">e_h</script>为隐层神经元梯度项，具体值如下：</p><script type="math/tex; mode=display">g_j=\hat{y_j}^k(1-\hat{y_j}^k)(y_j^k-\hat{y_j}^k)</script><script type="math/tex; mode=display">e_h=b_h(1-b_h)\sum_{j=1}^{l}w_{hj}g_j</script><blockquote><p>学习率<script type="math/tex">\eta\in(0,1)</script>控制着算法每一轮迭代中更新的步长（一般设置为0.1）：</p><ul><li><script type="math/tex">\eta</script>太大则容易震荡</li><li><script type="math/tex">\eta</script>太小则收敛速度过慢</li></ul></blockquote><p><strong>标准BP算法的工作流程</strong>：</p><ol><li><p>前向传播过程：输入示例传给输入层，再逐层将信号前传直到产生输出层结果；</p></li><li><p>反向传播过程：计算输出层输出误差（line4-5），再将误差逆传播至隐层神经元（line6），最后根据隐层神经元的误差来对连接权重和阈值进行调整（line7）。</p></li></ol><p><img src="/2023/06/08/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/标准BP算法流程.png" alt="标准BP算法流程"></p><h2 id="5-3-2-累积BP算法"><a href="#5-3-2-累积BP算法" class="headerlink" title="5.3.2 累积BP算法"></a>5.3.2 累积BP算法</h2><p>由于BP算法的目标是最小化训练集D上的累积误差<script type="math/tex">E=\frac{1}{m}\sum_{k=1}^{m}E_k</script>，标准BP算法的更新规则是基于for循环下的单个<script type="math/tex">E_k</script>推导而得到的，参数更新非常频繁且迭代次数多。若直接针对累积误差进行最小化，在读取训练集D一遍（一轮学习）后才进行参数更新，就得到了<strong>累积误差逆传播（accumulated error backpropagation）算法</strong>。</p><blockquote><p>注：标准BP算法和累积BP算法的区别类似于随机梯度下降与标准梯度下降的区别。</p></blockquote><p>累积BP算法参数更新的频率相对标准BP算法而言低很多。但在很多任务中，累积误差下降到一定程度后改变非常缓慢，这时标准BP算法往往会更快获得较好的解，在训练集D很大时尤其明显；如果数据集中的数据点之间的一致性较好，则采用累积BP算法往往更优。</p><h2 id="5-3-3-BP神经网络中的两个问题"><a href="#5-3-3-BP神经网络中的两个问题" class="headerlink" title="5.3.3 BP神经网络中的两个问题"></a>5.3.3 BP神经网络中的两个问题</h2><ul><li><strong>问题一：如何设置隐层神经元个数？</strong></li></ul><p><strong>通用近似定理/万能近似定理</strong>：只需一个包含足够多神经元的隐层，多层前馈神经网络能够以任意精度逼近任意复杂度的连续函数，该定理指出了人工神经网络近似任意模型（函数）的能力。</p><p>但如何设置隐层神经元个数仍是<strong>未决问题</strong>，实际运用中通常采用<strong>“试错法”（trail-by-error）</strong>进行调整。</p><ul><li><strong>问题二：如何解决过拟合问题？</strong></li></ul><p>由于BP神经网络的强大表示能力，因此其经常遭遇过拟合，其训练误差持续降低而测试误差仍在上升，常用的两种缓解策略如下：</p><ol><li><strong>早停法（early stopping）</strong>：将数据划分为训练集和验证集（validation set），训练集用来计算梯度、更新连接权重和阈值，验证集用来估计误差。若训练集误差不断降低但是验证集误差开始升高，则意味着此时出现过拟合，应停止训练，同时返回具有最小验证集误差的参数（连接权重和阈值）。</li><li><strong>正则化（regularization）</strong>：其基本思想是在误差目标函数中增加一个用于描述网络复杂度的部分，来限制模型的拟合能力。</li></ol><h1 id="5-4-全局最小和局部极小"><a href="#5-4-全局最小和局部极小" class="headerlink" title="5.4 全局最小和局部极小"></a>5.4 全局最小和局部极小</h1><p><strong>局部极小值陷阱</strong>：由于采用梯度下降法进行参数寻优，若误差函数在当前点的梯度为0则不再更新，此时达到了局部极小，这就意味着参数的迭代更新到此为止。但如果误差函数有多个局部极小，那么就不能保证当前找到的参数解是全局最小（最优），这就是局部极小值陷阱。</p><p><img src="/2023/06/08/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/全局最小与局部极小.png" alt="全局最小与局部极小"></p><p><strong>“跳出”局部极小值的方法</strong>：</p><ul><li>采用多组不同参数值初始化多个神经网络，训练后取其中误差最小的解作为最优参数。</li><li>采用模拟退火（simulated annealing）技术，在每一次迭代中都有一定概率接受“次优解”（概率要逐渐降低），从而有助于跳出局部极小。</li><li>使用随机梯度下降，引入随机因素。</li><li>使用遗传算法（genetic algorithms）来更好地逼近全局最小。</li></ul><blockquote><p>以上方法大多是启发式，理论上尚缺乏保障。</p></blockquote><h1 id="5-5-其他神经网络（简介）"><a href="#5-5-其他神经网络（简介）" class="headerlink" title="5.5 其他神经网络（简介）"></a>5.5 其他神经网络（简介）</h1><h2 id="5-5-1-径向基函数（RBF）网络"><a href="#5-5-1-径向基函数（RBF）网络" class="headerlink" title="5.5.1 径向基函数（RBF）网络"></a>5.5.1 径向基函数（RBF）网络</h2><p><strong>RBF网络</strong>：是一种单隐层前馈神经网络，并使用<strong>径向基函数</strong>（如高斯径向基函数<script type="math/tex">\rho(x,c_i)=e^{-\beta_i||x-c_i||^2}</script>）作为隐层神经元激活函数，而输出层则是对隐层神经元输出的线性组合。</p><p><strong>RBF网络训练过程</strong>：</p><ol><li>确定神经元中心（如聚类、随机采样等）</li><li>利用BP算法确定参数</li></ol><h2 id="5-5-2-自适应谐振理论（ART）网络"><a href="#5-5-2-自适应谐振理论（ART）网络" class="headerlink" title="5.5.2 自适应谐振理论（ART）网络"></a>5.5.2 自适应谐振理论（ART）网络</h2><p><strong>竞争型学习（competitive learning）</strong>：是神经网络中一种无监督学习策略，网络的输出神经元相互竞争，同一时刻只有一个胜者神经元被激活，其他被抑制【“胜者通吃”（winner-take-all）原则】。</p><p><strong>ART网络</strong>：主要思想是竞争型学习。该网络由比较层、识别层、识别阈值和重置模块构成.比较层负责接收输入样本，并将其传递给识别层神经元.识别层每个神经元对应 一个模式类，<strong>神经元数目可在训练过程中动态增长</strong>以增加新的模式类。</p><p><strong>ART网络优点</strong>：</p><ol><li>较好地缓解了竞争型学习中“可塑性-稳定性窘境”（stability plasticity dilemma）</li><li>可进行增量学习（incremental learning）或在线学习（online learning）</li></ol><h2 id="5-5-3-自组织映射（SOM）网络"><a href="#5-5-3-自组织映射（SOM）网络" class="headerlink" title="5.5.3 自组织映射（SOM）网络"></a>5.5.3 自组织映射（SOM）网络</h2><p><strong>SOM网络</strong>：是一种竞争学习型无监督神经网络。它能将<strong>高维输入数据映射到低维</strong>，同时保持其在高维空间中的拓扑结构。因此SOM的训练目标就是为每个输出层神经元找到合适的权向量，以达到保持拓扑结构的目的。</p><p><strong>SOM运用</strong>：聚类、高维数据可视化、图像分割等方面均有广泛运用。</p><p><img src="/2023/06/08/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/SOM.png" alt="SOM"></p><h2 id="5-5-4-级联相关（CCL）网络"><a href="#5-5-4-级联相关（CCL）网络" class="headerlink" title="5.5.4 级联相关（CCL）网络"></a>5.5.4 级联相关（CCL）网络</h2><p><strong>CCL网络</strong>：是结构适应网络（构造性神经网络）的代表，将网络结构也当作学习的目标之一，并希望能在训练过程中找到最符合数据特点的网络结构。</p><p><img src="/2023/06/08/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/CCL.png" alt="CCL"></p><p><strong>CCL网络中两个主要部分</strong>：</p><ol><li>“级联”：建立层次连接的层级结构（确定网络结构）</li><li>“相关”：通过最大化新神经元的输出与网络误差之间的相关性来训练参数（训练参数）</li></ol><blockquote><p>级联相关网络不需要设定网络层数和隐层神经元数量，且训练速度快，但在数据较小时易陷入过拟合。</p></blockquote><h2 id="5-5-5-Elman网络"><a href="#5-5-5-Elman网络" class="headerlink" title="5.5.5 Elman网络"></a>5.5.5 Elman网络</h2><p><strong>Elman网络</strong>：是递归神经网络（recurrent neural networks）的一种，允许网络中出现环形结构。它的结构与多层前馈网络相似，但隐层神经元输出被反馈回来称为神经元下一时刻输入的一部分。</p><p><img src="/2023/06/08/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/Elman.png" alt="Elman"></p><h2 id="5-5-6-Boltzmann机"><a href="#5-5-6-Boltzmann机" class="headerlink" title="5.5.6 Boltzmann机"></a>5.5.6 Boltzmann机</h2><p><strong>Boltzmann机</strong>：是一种“基于能量的模型”（energy-based model），为网络状态定义一个Boltzmann机能量，网络的训练就是在最小化这个能量函数使得网络达到理想状态——Boltzmann分布。现实中常采用的是受限的Boltzmann机（Restricted Boltzmann Machine，简称RBM）。</p><p><img src="/2023/06/08/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/Boltzmann机和RBM.png" alt="Boltzmann机和RBM"></p><h1 id="5-6-深度学习"><a href="#5-6-深度学习" class="headerlink" title="5.6 深度学习"></a>5.6 深度学习</h1><p><strong>深度学习（deep learning） = 表示学习（representation learning）/特征学习（feature learning） + 机器学习</strong></p>]]></content>
      
      
      <categories>
          
          <category> ML study </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning, Deep Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>周志华《机器学习》（AKA：西瓜书）笔记整理-第四章-决策树</title>
      <link href="/2023/06/07/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/"/>
      <url>/2023/06/07/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/</url>
      
        <content type="html"><![CDATA[<h1 id="4-1-基本流程"><a href="#4-1-基本流程" class="headerlink" title="4.1 基本流程"></a>4.1 基本流程</h1><p><strong>决策树（decision tree）</strong>：基于树型结构进行模型的分类决策，决策过程的最终结论对应了我们所希望的判定结果。一般的，一棵决策树包含了一个根节点、若干个内部节点和若干个叶节点；叶节点对应决策结果，而其他内部节点对应一个属性测试，根节点则包含了样本全集。决策树的学习目的是为了产生一棵泛化能力强的决策树，其基本流程遵循简单而直观的<strong>“分而治之（divide-and-conquer）”</strong>策略。</p><p><img src="/2023/06/07/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/决策树.png" alt="决策树"></p><p><img src="/2023/06/07/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/决策树基本算法.png" alt="决策树基本算法"></p><blockquote><p>决策树生成是一个递归过程，有三种情况会导致递归返回</p><ol><li>当前节点包含的样本全部属于同一类别——无需划分</li><li>当前属性集为空，或者是所有样本在所有属性上取值相同——无法划分</li><li>当前节点包含的样本集合为空——不能划分</li></ol></blockquote><h1 id="4-2-划分选择"><a href="#4-2-划分选择" class="headerlink" title="4.2 划分选择"></a>4.2 划分选择</h1><p>决策树学习的关键在于<strong>如何选择最优划分属性</strong>。一般而言，随着划分过程的不断进行，我们希望决策树的分支节点所包含的样本尽可能属于同一类别，即节点的<strong>“纯度”（purity）</strong>越来越高。</p><h2 id="4-2-1-信息增益"><a href="#4-2-1-信息增益" class="headerlink" title="4.2.1 信息增益"></a>4.2.1 信息增益</h2><p><strong>信息熵（information entropy）</strong>：度量样本纯度的常用指标。假定当前样本集合D中第k类样本所占比例为<script type="math/tex">p_k</script>，则D的信息熵定义为</p><script type="math/tex; mode=display">Ent(D)=-\sum_k{p_klog_2p_k}</script><p>Ent(D)的值越小，D的纯度越高。</p><p><strong>信息增益（information gain）</strong>：使用属性a对样本集D进行划分前后的信息熵之差。假定在属性a熵有V个可能取值，则信息增益为</p><script type="math/tex; mode=display">Gain(D,a)=Ent(D)-\sum_{v=1}^{V}{\frac{|D^v|}{|D|}Ent(D^v)}</script><p>一般而言，信息增益越大，则意味着用属性a进行划分所获得的“纯度提升”越大。因此，我们可以用信息增益来作为决策树划分属性的选择标准，即在决策树学习基本算法的第八行选择属性<script type="math/tex">a^*=\underset{a\in A}{\arg\max}\ Gain(D,a)</script>。</p><blockquote><p>著名的ID3决策树学习算法就是以信息增益为准则来划分最优属性。</p></blockquote><p>注：信息增益准则对可取值数目较多的属性有所偏好。</p><h2 id="4-2-1-增益率"><a href="#4-2-1-增益率" class="headerlink" title="4.2.1 增益率"></a>4.2.1 增益率</h2><p><strong>增益率（gain ratio）</strong>：在信息增益的基础上去除分叉本身带来的熵增益，增益率定义为</p><script type="math/tex; mode=display">Gain_ratio(D,a)=\frac{Gain(D,a)}{IV(a)}</script><script type="math/tex; mode=display">其中：IV(a)=-\sum_{v=1}^{V}\frac{|D^v|}{|D|}log_2\frac{|D^v|}{|D|}</script><p>IV(a)称为属性a的固有值（intrinsic value）。属性a的可取值数目越多（V越大），则IV(a)的值越大。</p><blockquote><p>著名的C4.5决策树算法使用增益率准则来选择最优划分属性，实际上是选择信息增益高于平均水平且信息增益率最大的属性。</p></blockquote><p>注：增益率准则对可取值数目较少的属性有所偏好。</p><h2 id="4-2-3-基尼指数"><a href="#4-2-3-基尼指数" class="headerlink" title="4.2.3 基尼指数"></a>4.2.3 基尼指数</h2><p><strong>基尼值（Gini value）</strong>：度量数据集D的纯度的指标，反映了从数据集D中随机抽取两个样本，其类别标记不一致的概率。基尼值定义为</p><script type="math/tex; mode=display">Gini(D)=1-\sum_k{p_k^2}</script><p>Gini(D)的值越小，数据集D的纯度越高。</p><p><strong>基尼指数（Gini index）</strong>：假定使用属性a进行划分，基尼指数定义为</p><script type="math/tex; mode=display">Gini\_index(D,a)=\sum_{v=1}^{V}{\frac{|D^v|}{|D|}Gini(D^v)}</script><p>在划分属性是选择基尼指数最小的值作为最优划分属性，即<script type="math/tex">a^*=\underset{a\in A}{\arg\min}\ Gini\_index(D,a)</script>。</p><blockquote><p>CART决策树（分类回归树，一定是二叉树）使用基尼指数来选择划分属性。</p></blockquote><h1 id="4-3-剪枝处理"><a href="#4-3-剪枝处理" class="headerlink" title="4.3 剪枝处理"></a>4.3 剪枝处理</h1><p><strong>剪枝（pruning）</strong>：是决策树学习算法对付“过拟合”的重要手段。由于决策树分支过多，可能把训练集中的一些特性当作所有数据的一般性质，因此十分容易导致过拟合。</p><h2 id="4-3-1-预剪枝"><a href="#4-3-1-预剪枝" class="headerlink" title="4.3.1 预剪枝"></a>4.3.1 预剪枝</h2><p><strong>预剪枝（prepruning）</strong>：在决策树生成过程中，对每一个节点在<strong>划分前</strong>进行估计，若当前节点的划分不能带来决策树泛化性能的提升，则停止划分，并将当前节点标记为叶节点。</p><p><img src="/2023/06/07/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/预剪枝.png" alt="预剪枝"></p><blockquote><p>预剪枝决策树的<strong>优点</strong>：</p><ol><li>降低了过拟合的风险</li><li>显著减少了决策树的训练时间开销和测试时间开销</li></ol><p>预剪枝决策树的<strong>缺点</strong>：</p><ol><li>虽然有些分支的当前划分不能提升泛化性能（甚至下降），但在其基础上进行的后续划分却有可能显著提升决策树的泛化性能，预剪枝算法基于“贪心”本质禁止这些分支展开，给预剪枝决策树带来了欠拟合风险</li></ol></blockquote><h2 id="4-3-2-后剪枝"><a href="#4-3-2-后剪枝" class="headerlink" title="4.3.2 后剪枝"></a>4.3.2 后剪枝</h2><p><strong>后剪枝（postpruning）</strong>：先从训练集中生成一棵<strong>完整的决策树</strong>，然后自底向上对非叶节点进行考察，若该节点对应的子树替换为叶节点能带来决策树泛化性能的提升，则将该子树替换为叶节点，否则保持不变。</p><p><img src="/2023/06/07/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/后剪枝.png" alt="后剪枝"></p><blockquote><p>后剪枝决策树的<strong>优点</strong>：</p><ol><li>保留了更多的分支，使得欠拟合风险很小</li><li>泛化性能往往优于预剪枝决策树</li></ol><p>后剪枝决策树的<strong>缺点</strong>：</p><ol><li>训练时间开销比未剪枝决策树和预剪枝决策树都大很多</li></ol></blockquote><h1 id="4-4-连续与缺失值"><a href="#4-4-连续与缺失值" class="headerlink" title="4.4 连续与缺失值"></a>4.4 连续与缺失值</h1><h2 id="4-4-1-连续值处理"><a href="#4-4-1-连续值处理" class="headerlink" title="4.4.1 连续值处理"></a>4.4.1 连续值处理</h2><p><strong>连续属性离散化技术</strong>：最简单的策略是采用<strong>二分法（bi-partition）</strong>，C4.5决策树正是采用了这种机制。</p><p>具体步骤：</p><p>Step1：排序。假设连续属性a在样本集D上出现了n个不同的取值，将这些值<strong>从小到大</strong>排序。</p><p>Step2：找划分点集合。对于出现n个值的连续属性a，我们可考察n-1个候选划分点所组成的划分点集合</p><script type="math/tex; mode=display">T_a=\{\frac{a^i+a^{i+1}}{2}|1\leq i\leq n-1\}</script><p>Step3：找最优划分点。样本集D基于划分点t二分后所带来的信息增益定义为：</p><script type="math/tex; mode=display">Gain(D,a,t)=Ent(D)-\sum_{\lambda\in\{-,+\}}\frac{|D_t^\lambda|}{|D|}Ent(D_t^\lambda)</script><p>于是，我们就选择使Gain(D,a,t)最大化的划分点。</p><blockquote><p>注意：与离散属性不同，若当前节点划分属性为连续属性，该属性还可以作为其后代节点的划分属性，只需要改变阈值即可（能在算法内部解决）。</p></blockquote><h2 id="4-4-2-缺失值处理"><a href="#4-4-2-缺失值处理" class="headerlink" title="4.4.2 缺失值处理"></a>4.4.2 缺失值处理</h2><p>现实任务中常会遇到不完整的样本，即样本的某些属性值缺失。考虑两个问题：</p><ul><li><strong>问题一：如何在属性值缺失的情况下进行划分属性选择？</strong></li></ul><p>首先为每个样本x赋予一个权重<script type="math/tex">w_x</script>。对于属性a，令<script type="math/tex">\tilde{D}</script>表示在属性a上没有缺失值的样本子集，<script type="math/tex">\rho</script>表示无缺失样本占比，<script type="math/tex">\tilde{p_k}</script>表示无缺失样本中第k类占比，<script type="math/tex">\tilde{r_v}</script>表示无缺失样本中在属性a上取值为<script type="math/tex">a^v</script>的样本占比。基于这些定义，可将信息增益的计算式推广为</p><script type="math/tex; mode=display">Gain(D,a)=\rho\times Gain(\tilde D,a)=\rho \times \Big(Ent(\tilde D)-\sum_v{\tilde r_vEnt(\tilde D^v)}\Big)</script><script type="math/tex; mode=display">其中：Ent(\tilde D)=-\sum_k{\tilde p_klog_2\tilde p_k},\ t\in T_a</script><ul><li><strong>问题二：给定了划分属性，若样本在该属性上的值缺失，如何进行样本划分？</strong></li></ul><ol><li>若样本x在划分属性a上的取值已知，则将x划入与其取值对应的子节点，且样本权重在子节点中保持为<script type="math/tex">w_x</script>。</li><li>若样本x在划分属性a上的取值未知，则将x同时划入所有子节点，且在属性值<script type="math/tex">a^v</script>对应的子节点中样本权重调整为<script type="math/tex">\tilde{r_v}w_x</script>（让同一样本以不同概率划入到不同的子节点中）。</li></ol><blockquote><p>C4.5决策树算法使用了上述方案。</p></blockquote><h1 id="4-5-多变量决策树"><a href="#4-5-多变量决策树" class="headerlink" title="4.5 多变量决策树"></a>4.5 多变量决策树</h1><p>若将每个划分属性视作坐标空间中的一个坐标轴，则d个属性描述的样本就对应了d维空间中的一个数据点，对样本分类的过程可以视为在这个坐标空间中寻找不同类样本的分类边界，而<strong>决策树的样本分类边界则一定是与坐标轴平行的</strong>。在现实任务中，学习任务的分类边界往往比较复杂，需要有很多的分段才能有较好的近似，此时的决策树会相当复杂，需要进行大量的属性测试，时间开销大。</p><p><strong>多变量决策树（multicariate decision tree）</strong>：实现“斜划分”甚至更复杂划分的决策树。</p><p><img src="/2023/06/07/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/多变量决策树.png" alt="多变量决策树"></p>]]></content>
      
      
      <categories>
          
          <category> ML study </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>周志华《机器学习》（AKA：西瓜书）笔记整理-第三章-线性模型</title>
      <link href="/2023/06/06/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%B8%89%E7%AB%A0-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
      <url>/2023/06/06/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%B8%89%E7%AB%A0-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<blockquote><p>机器学习三要素：</p><p>模型——根据具体问题，确定假设空间</p><p>策略——根据评价标准，确定选取最优模型的策略</p><p>算法——求解损失函数，确定最终模型</p></blockquote><h1 id="3-1-基本形式"><a href="#3-1-基本形式" class="headerlink" title="3.1 基本形式"></a>3.1 基本形式</h1><p><strong>线性模型（linear model）</strong>：试图学得一个通过属性的线性组合来进行预测的函数。</p><ul><li>一般形式</li></ul><script type="math/tex; mode=display">f(x)=w_1x_1+w_2x_2+...+w_dx_d+b</script><ul><li>向量形式</li></ul><script type="math/tex; mode=display">f(x)=w^Tx+b</script><h1 id="3-2-线性回归-linear-regression"><a href="#3-2-线性回归-linear-regression" class="headerlink" title="3.2 线性回归(linear regression)"></a>3.2 线性回归(linear regression)</h1><h2 id="3-2-1-一元线性回归（只有一个输入属性）"><a href="#3-2-1-一元线性回归（只有一个输入属性）" class="headerlink" title="3.2.1 一元线性回归（只有一个输入属性）"></a>3.2.1 一元线性回归（只有一个输入属性）</h2><p><strong>一元线性回归</strong>试图学得：</p><script type="math/tex; mode=display">f(x_i)=wx_i+b, 使得f(x_i\simeq y_i)</script><p>采用均方误差作为性能度量，并对均方误差进行最小化：</p><script type="math/tex; mode=display">(w^*,b^*)= \underset{(w, b)}{\arg\min}{\sum_{i=1}^m{(f(x_i)-y_i)^2}}=\underset{(w,b)}{\arg\min}{\sum_{i=1}^m{(y_i-wx_i-b)^2}}</script><p>采用最小二乘法分别对w和b求导并赋0，可以得到w和b最优解的闭式解：</p><script type="math/tex; mode=display">w=\frac{\sum_{i=1}^m{y_i(x_i-\bar x)}}{\sum_{i=1}^mx_i^2-\frac{1}{m}(\sum_{i=1}^m{x_i})^2}</script><script type="math/tex; mode=display">b=\frac{1}{m}\sum_{i=1}^{m}{(y_i-wx_i)}</script><h2 id="3-2-2-多元线性回归（有d个输入属性）"><a href="#3-2-2-多元线性回归（有d个输入属性）" class="headerlink" title="3.2.2 多元线性回归（有d个输入属性）"></a>3.2.2 多元线性回归（有d个输入属性）</h2><p><strong>多元线性回归</strong>试图学得：</p><script type="math/tex; mode=display">f(x_i)=w^Tx_i+b_i,使得f(x_i)\simeq y_i</script><p>将w和b吸收入向量形式<script type="math/tex">\hat w=(w;b)</script>，则上式可化为：</p><script type="math/tex; mode=display">f(x)=\hat w^TX,其中\hat w=[b,w_1,w_2,...,w_d]^T,X=[1,x_1,x_2,...,x_d]^T</script><ul><li><strong>方法一：梯度下降法（Gradient Descent）</strong></li></ul><p>代价函数（cost function）：<script type="math/tex">J(\hat w)=\frac{1}{2m}\sum_{i=1}^{m}{(f(x_i)-y_i)^2}</script></p><p>梯度下降：</p><p>Repeat {</p><p>​    <script type="math/tex">\hat w_j:=\hat w_j-\alpha\frac{\partial}{\partial\hat{w}_j}J(\hat{w})</script>    for every j = 0, 1, …, d</p><p>} until convergence</p><p>其中<script type="math/tex">\alpha</script>为学习率。若<script type="math/tex">\alpha</script>过小，收敛速度太慢；若<script type="math/tex">\alpha</script>过大，则容易跳过极值点。选取<script type="math/tex">\alpha</script>时可以隔10倍取值进行尝试。</p><p>缺点：需要多次选择学习率<script type="math/tex">\alpha</script>，运行多次确定最好的值；需要更多次的迭代。</p><ul><li><strong>方法二：正规方程法（Normal Equation）</strong></li></ul><p>优化目标：<script type="math/tex">\hat{w}^*=\underset{\hat{w}}{\arg\min}(y-X\hat{w})^T(y-X\hat{w})</script></p><p>对<script type="math/tex">\hat{w}</script>求导并赋0得：<script type="math/tex">\hat{w}^*=(X^TX)^{-1}X^Ty</script></p><p>缺点：<script type="math/tex">(X^TX)^{-1}</script>求解麻烦，时间复杂度高，特征量越多计算越复杂。</p><blockquote><p>梯度下降法和正规方程法对比</p><div class="table-container"><table><thead><tr><th style="text-align:center">梯度下降法</th><th style="text-align:center">正规方程法</th></tr></thead><tbody><tr><td style="text-align:center">需要选择学习率</td><td style="text-align:center">不需要选择学习率</td></tr><tr><td style="text-align:center">需要迭代求解</td><td style="text-align:center">一蹴而就</td></tr><tr><td style="text-align:center">特征数量比较大时可以使用</td><td style="text-align:center">需要计算方程，时间复杂度高</td></tr></tbody></table></div><p><strong>若特征量d很大（大于1000），则选择梯度下降法，否则选择正规方程法。</strong></p></blockquote><h1 id="3-3-对数几率回归（逻辑回归）"><a href="#3-3-对数几率回归（逻辑回归）" class="headerlink" title="3.3 对数几率回归（逻辑回归）"></a>3.3 对数几率回归（逻辑回归）</h1><p><strong>对数几率回归（logistic regression）</strong>：虽然名字叫做回归，但是实际上解决的是分类问题。主要思想是找到一个单调可微函数将分类任务的真实标记y和线性回归模型的预测值f(x)联系起来。</p><p><strong>联系函数（link function）</strong>：</p><ul><li><strong>单位阶跃函数（unit-step function）</strong>:</li></ul><script type="math/tex; mode=display">y=\begin{cases}0,\quad z<0\\0.5,\quad z=0\\1,\quad z>0\end{cases}</script><p>注：该函数是分段函数，不便于求解，因此不能直接作为联系函数来使用。</p><ul><li><strong>对数几率函数（logistic function）</strong>：</li></ul><script type="math/tex; mode=display">y=\frac{1}{1+e^{-z}}</script><p>注：该函数是一种<strong>“Sigmoid”函数</strong>，将z值转换为一个接近0或1的y值，并且在z=0附近变化很陡，故采用。将<script type="math/tex">z=w^Tx+b</script>代入可得<script type="math/tex">y=\frac{1}{1+e^{-(w^Tx+b)}}</script>。</p><p><img src="/2023/06/06/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%B8%89%E7%AB%A0-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/单位阶跃函数和对数几率函数.png" alt="单位阶跃函数和对数几率函数"></p><p>可以通过<strong>“极大似然法”（maximum likelihood method, MLE）</strong>来估计参数w和b（合起来写作<script type="math/tex">\hat{w}</script>），并采用<strong>对数似然法（log-likelihood）</strong>简化计算，得到代价函数：</p><script type="math/tex; mode=display">J(\hat{w})=\frac{1}{m}\sum_{i=1}^{m}{cost(f(x_i),y_i)}</script><script type="math/tex; mode=display">其中：cost(f(x), y)=\begin{cases}-log(f(x)), \quad y=1\\-log(1-f(x)), \quad y=0\end{cases}</script><p>将该分段函数写成一个式子（方法不唯一）：</p><script type="math/tex; mode=display">cost(f(x),y)=-ylog(f(x))-(1-y)log(1-f(x))</script><p>最终<strong>优化目标</strong>是：</p><script type="math/tex; mode=display">\hat{w}=\underset{\hat{w}}{\arg\min}\frac{1}{m}\sum_{i=1}^{m}\Big[{y_ilog(f(x_i))+(1-y_i)log(1-f(x_i))}\Big]</script><ul><li><strong>方法一：梯度下降法（和线性回归的梯度下降一样，只不过代价函数不同）</strong></li></ul><p>​    Repeat {</p><p>​            <script type="math/tex">\hat w_j:=\hat w_j-\alpha\frac{\partial}{\partial\hat{w}_j}J(\hat{w})</script>    for every j = 0, 1, …, d</p><p>​    } until convergence</p><ul><li><strong>方法二：牛顿法（Newton Method）</strong></li></ul><p>第t+1轮迭代解的更新公式是：</p><script type="math/tex; mode=display">\hat{w}^{t+1}:=\hat{w}^t-\Big(\frac{\partial^2J(\hat{w})}{\partial{\hat{w}}\partial{\hat{w}^T}}\Big)^{-1}\frac{\partial{J(\hat{w})}}{\partial\hat{w}}</script><blockquote><p>其他高级优化算法</p><ul><li>共轭梯度法</li><li>BFGS</li><li>L-BFGS（在有限内存中进行BFGS算法）</li></ul><p>优点：不需要手动选择学习率<script type="math/tex">\alpha</script>，收敛速度远快于梯度下降</p><p>缺点：更为复杂</p></blockquote><h1 id="（补充）广义线性模型（generalized-linear-model-GLM）"><a href="#（补充）广义线性模型（generalized-linear-model-GLM）" class="headerlink" title="（补充）广义线性模型（generalized linear model, GLM）"></a>（补充）广义线性模型（generalized linear model, GLM）</h1><p><strong>1. 指数族分布（exponential families of distributions）</strong>：具有如下特定形式的概率分布的参数集合</p><script type="math/tex; mode=display">P_X(x|\theta)=h(x)exp(\eta(\theta)T(x)-A(\theta))</script><p>其中：x是数据（data），<script type="math/tex">\theta</script>是自然参数（natural parameter），T(x)是充分统计量（sufficiant statistic），h(x)是基本度量（Base measure），<script type="math/tex">A(\theta)</script>是log配分函数（log partition-function）</p><blockquote><ol><li><p>指数族分布满足最大熵原理</p></li><li><p>诸如高斯分布、伯努利分布、二项分布、泊松分布、Beta分布、Gamma分布等一系列分布都属于指数族分布</p></li></ol></blockquote><p><strong>2. 广义线性模型（GLM）的运用</strong>：</p><p>GLM的<strong>三个假设</strong>：</p><ol><li><p><script type="math/tex">y|x;\hat{w}</script>满足一个以<script type="math/tex">\eta</script>为自然参数的指数族分布，那么可以求得<script type="math/tex">\eta</script>的表达式；</p></li><li><p>给定x，我们的目标是预测T(y)的期望值，大多数情况下可以认为T(y)=y，因此我们实际上是要确定一个h(x)使得h(x)=E[y|x]；</p></li><li><p>重新表示<script type="math/tex">\eta=\hat{w}^Tx</script>。</p></li></ol><p><strong>具体步骤</strong>：</p><p>Step1：核心假设<script type="math/tex">y\sim exponential family</script></p><div class="table-container"><table><thead><tr><th style="text-align:center">样本标签y的类型</th><th style="text-align:center">选择的指数族分布</th></tr></thead><tbody><tr><td style="text-align:center">Real</td><td style="text-align:center">Gaussian</td></tr><tr><td style="text-align:center">Binary</td><td style="text-align:center">Bernoulli</td></tr><tr><td style="text-align:center">Count</td><td style="text-align:center">Poisson</td></tr><tr><td style="text-align:center"><script type="math/tex">R^2</script></td><td style="text-align:center">Gamma, Exponential</td></tr><tr><td style="text-align:center">Distn</td><td style="text-align:center">Beta, Dirichlet</td></tr></tbody></table></div><p>Step2：将具体分布改写为指数族分布的形式，利用响应函数（response function）和连接函数（link function）找到规范参数（canonical parameter）和自然参数<script type="math/tex">\eta</script>之间的关系</p><p>Step3：将自然参数<script type="math/tex">\eta</script>用<script type="math/tex">\hat{w}^Tx</script>代替</p><p>Step4：模型求解</p><blockquote><p>注：自然参数<script type="math/tex">\eta</script>以不同的映射函数与其他概率分布函数中的参数（规范参数）发生联系，从而得到不同的模型，广义线性模型正是将指数族分布中的所有成员（每个成员正好有一个这样的联系）都作为线性模型的拓展，通过各种非线性的连接函数将线性函数映射到其他空间，从而大大扩大了线性模型可解决的问题。</p></blockquote><p><strong>3. 广义线性模型运用举例——softmax回归</strong>:</p><p>softmax回归也是广义线性模型的一种实现，主要是用于解决多分类任务。假设y的估值概率属于指数分布族中的多项式分布，即<script type="math/tex">y|x,\hat{w}\sim Mult(\phi)</script>，通过一系列推导（<em>参见：<a href="https://www.jianshu.com/p/e2cf48dd8e40">广义线性模型和softmax回归</a></em>）可以得到最终回归模型为：</p><script type="math/tex; mode=display">f(x;\hat{w})=\left[\begin{matrix}\frac{e^{\hat{w}_1^Tx}}{\sum_{i=1}^{d}{e^{\hat{w_i}^Tx}}}\\\frac{e^{\hat{w}_2^Tx}}{\sum_{i=1}^{d}{e^{\hat{w_i}^Tx}}}\\\vdots\\\frac{e^{\hat{w}_{d-1}^Tx}}{\sum_{i=1}^{d}{e^{\hat{w_i}^Tx}}}\end{matrix}\right]</script><p>利用极大似然估计法，得到回归模型的交叉熵代价函数：</p><script type="math/tex; mode=display">J(\hat{w})=-\frac{1}{m}\Bigg[\sum_{i=1}^{m}\sum_{j=1}^d\amalg(y_i=j)log\frac{e^{\hat{w}_j^Tx_i}}{\sum_{l=1}^{k}{e^{\hat{w}_l^Tx_i}}}\Bigg]</script><p>最后采用梯度下降法对模型进行求解，更新公式为：</p><script type="math/tex; mode=display">\hat w_j:=\hat w_j-\alpha\frac{\partial}{\partial\hat{w}_j}J(\hat{w})</script><h1 id="3-4-线性判别分析（Linear-Discriminate-Analysis-LDA）"><a href="#3-4-线性判别分析（Linear-Discriminate-Analysis-LDA）" class="headerlink" title="3.4 线性判别分析（Linear Discriminate Analysis, LDA）"></a>3.4 线性判别分析（Linear Discriminate Analysis, LDA）</h1><p><strong>主要思想</strong>：给定训练样例集，设法将样本点投影到一条直线上，使得同类样本的投影点尽可能接近、异类样本的投影点尽可能远离；在对新样本分类时也是先将其投影到这条直线上，再根据投影点的位置作出判断。</p><p><img src="/2023/06/06/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%B8%89%E7%AB%A0-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/LDA.png" alt="LDA"></p><h2 id="3-4-1-二分类任务"><a href="#3-4-1-二分类任务" class="headerlink" title="3.4.1 二分类任务"></a>3.4.1 二分类任务</h2><p>令<script type="math/tex">X_i</script>、<script type="math/tex">\mu_i</script>、<script type="math/tex">\Sigma_i</script>表示第i类样本的集合、均值向量、协方差矩阵，并将样本点投影至直线<script type="math/tex">y=w^Tx</script>上。</p><ul><li>类内散度矩阵（within-class scatter matrix）：刻画同类样本投影点之间的距离</li></ul><script type="math/tex; mode=display">S_w=\Sigma_0+\Sigma_1=\sum_{x\in X_0}{(x-\mu_0)^T(x-\mu_0)}+\sum_{x\in X_1}{(x-\mu_1)^T(x-\mu_1)}</script><ul><li>类间散度矩阵（between-class scatter matrix）：刻画异类样本投影点中心之间的距离</li></ul><script type="math/tex; mode=display">S_b=(\mu_0-\mu_1)(\mu_0-\mu_1)^T</script><p><strong>最优化目标</strong>为：</p><script type="math/tex; mode=display">\begin{split}\underset{w}{min}\ -w^TS_bw\\s.t.\ w^TS_ww=1\end{split}</script><p>采用拉格朗日乘子法求解，得到：</p><script type="math/tex; mode=display">w^*=S_w^{-1}(\mu_0-\mu_1)</script><blockquote><p>上式可对<script type="math/tex">S_w</script>进行奇异值分解的方式求解<script type="math/tex">S_w^{-1}</script>。</p></blockquote><h2 id="3-4-2-多分类任务"><a href="#3-4-2-多分类任务" class="headerlink" title="3.4.2 多分类任务"></a>3.4.2 多分类任务</h2><ul><li>全局散度矩阵：</li></ul><script type="math/tex; mode=display">S_t=S_b+S_w=\sum_{i=1}^m{(x_i-\mu)(x_i-\mu)^T}</script><p>显然，多分类LDA可以有多种实现方法：使用<script type="math/tex">S_b</script>、<script type="math/tex">S_w</script>、<script type="math/tex">S_t</script>三者中的任意两个即可，通常采用如下<strong>最优化目标</strong>：</p><script type="math/tex; mode=display">\underset{W}{max}\frac{tr(W^TS_bW)}{tr(W^TS_wW)}</script><p>W的闭式解则是<script type="math/tex">S_w^{-1}S_b</script>的d‘（<script type="math/tex">d’\leq N-1</script>）个最大非零广义特征值所对应的特征向量组成的矩阵。</p><blockquote><p>可以认为这d‘个特征向量是“最具特征的”。</p></blockquote><h1 id="3-5-多分类学习"><a href="#3-5-多分类学习" class="headerlink" title="3.5 多分类学习"></a>3.5 多分类学习</h1><p><strong>基本策略</strong>：利用二分类学习器解决多分类问题</p><ul><li>“一对一”（OvO）：将N个类别两两配对，从而产生N(N-1)/2个二分类任务，最终结果通过投票产生。</li><li>“一对多”（OvR）：每次将一个类的样例作为正例，其余类的样例作为反例来训练N个分类器。</li></ul><p><img src="/2023/06/06/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%B8%89%E7%AB%A0-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/OvO和OvR.png" alt="OvO和OvR"></p><ul><li>“多对多”（MvM）：每次将若干个类作为正类，若干个其他类作为反类。</li></ul><h1 id="3-6-类别不平衡问题"><a href="#3-6-类别不平衡问题" class="headerlink" title="3.6 类别不平衡问题"></a>3.6 类别不平衡问题</h1><p><strong>类别不平衡（class-imbalance）</strong>：是指分类任务中不同类别的训练样例数目差别很大。</p><p><strong>基本策略</strong>：再缩放（rescaling）</p><p><strong>解决方法</strong>：</p><ol><li>对较多的样本进行欠采样，eg. SMOTE（插值产生额外样例）</li><li>对较少的样本进行过采样，eg. EasyEnsemble（利用集成学习将样例划分为若干个集合）</li><li>阈值移动（threshold-moving）</li></ol>]]></content>
      
      
      <categories>
          
          <category> ML study </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>周志华《机器学习》（AKA：西瓜书）笔记整理-第二章-模型评估与选择</title>
      <link href="/2023/06/05/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/"/>
      <url>/2023/06/05/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/</url>
      
        <content type="html"><![CDATA[<h1 id="2-1-经验误差与过拟合"><a href="#2-1-经验误差与过拟合" class="headerlink" title="2.1 经验误差与过拟合"></a>2.1 经验误差与过拟合</h1><p><strong>错误率（error rate）</strong>：分类错误的样本数占样本总数的比例。如果在m个样本中有a个样本分类错误，则错误率为$E = \frac{a}{m}$ 。</p><p><strong>精度（accuracy）</strong>：精度=1-错误率。<br><strong>误差（error）</strong>：学习器的实际预测输出与样本的真实输出之间的差异。<br><strong>训练误差（training error）/经验误差（empirical error）</strong>：学习器在训练集上的误差。<br><strong>泛化误差（generalization error）</strong>：学习器在新样本上的误差（我们希望得到泛化误差小的学习器）。</p><p><strong>过拟合</strong>：在训练集上表现很好，但在测试集上表现不好（学习能力太强，不可避免，只能缓解）。<br><strong>欠拟合</strong>：在训练集和测试集上表现都不好（学习能力太弱，加大学习）。</p><blockquote><p>解决过拟合的方法：</p><p>​    1.降低参数空间的维度（如剪枝、权重共享等）<br>​    2.降低每个参数维度上的有效规模（如正则化、早停法、训练更多数据等）</p><p>解决欠拟合的方法：</p><p>​    1.增加新的特征或多项式特征<br>​    2.使用非线性模型等更复杂的模型<br>​    3.使用集成学习方法，如Bagging等</p></blockquote><p><strong>补充</strong>：</p><p>P类问题（Polynominal problem）：存在多项式时间算法问题。</p><p>NP类问题（Nondeterministic Polynominal-hard problem）：能在多项式时间内验证得出一个正确的解。</p><p>NP难问题（NP-hard problem）：无法得到多项式级的算法。</p><h1 id="2-2-评估方法"><a href="#2-2-评估方法" class="headerlink" title="2.2 评估方法"></a>2.2 评估方法</h1><p><strong>测试集（testing set）</strong>：来测试学习器对新样本的判别能力。</p><ul><li>从样本真实分布中独立同分布（iid）采样而得</li><li>尽可能与训练集互斥</li></ul><p><strong>测试误差（testing error）</strong>：作为泛化误差的近似。</p><h2 id="2-2-1-留出法（hold-out）"><a href="#2-2-1-留出法（hold-out）" class="headerlink" title="2.2.1 留出法（hold-out）"></a>2.2.1 留出法（hold-out）</h2><p>直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S（$70\%-80\% $），另一个作为测试集T（$20\%-30\%$）。</p><blockquote><p>以二分类任务为例子，假定D中有1000个样本，划分后S包含700个样本T包含300个样本，用S进行训练之后，若模型在T上有90个样本分类错误，那么错误率为$(90/300)\times100\% = 30\%$，相应的精度为$1-30\%= 70\%$。</p></blockquote><p><strong>注意</strong>：单次使用留出法时得到的估计结果往往不够稳定可靠，因此一般要采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果。</p><h2 id="2-2-2-交叉验证法（cross-validation）"><a href="#2-2-2-交叉验证法（cross-validation）" class="headerlink" title="2.2.2 交叉验证法（cross validation）"></a>2.2.2 交叉验证法（cross validation）</h2><p>将数据集D划分为k个大小相似的互斥子集，每个子集都从D中通过分层残阳得到（尽可能保持数据分布一致性），然后每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集，最终返回的是k个测试结果的均值。</p><ul><li><p><strong>k折交叉验证（k-fold cross validation）</strong>：k最常用的取值是10，此外还常用的有5、20等。</p><p><img src="/2023/06/05/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/10折交叉验证示意图.png" alt="10折交叉验证示意图"></p><center>10折交叉验证示意图</center><p>为减少因样本划分不同而引入的差别，k折交叉验证通常要随机使用不同的划分重复p次，最终评估结果是折p次k折交叉验证结果的均值。</p></li><li><p><strong>留一法（Leave-One-Out，简称LOO）</strong>：k=m，m为样本个数，数据集较大时不推荐使用。</p></li></ul><h2 id="2-2-3-自助法（bootstrapping）"><a href="#2-2-3-自助法（bootstrapping）" class="headerlink" title="2.2.3 自助法（bootstrapping）"></a>2.2.3 自助法（bootstrapping）</h2><p>直接以自助手采样（bootstrap sampling）为基础。在包含m个样本的数据集D中<strong>有放回</strong>地采样m次得到数据集D’，初始数据集D中约有36.8%的样本未出现在采样数据集D’中，于是我们把D’作为训练集，D\D‘作为测试集。这样，我们仍有数据总量约1/3的、没在训练集中出现的样本用于测试，这样的测试结果也叫做<strong>“包外估计”（out-of-bag estimate）</strong>。</p><p><strong>缺点</strong>：自助法产生的数据集改变了初始数据集的分布，会引入估计偏差。</p><h2 id="2-2-4-调参与最终模型"><a href="#2-2-4-调参与最终模型" class="headerlink" title="2.2.4 调参与最终模型"></a>2.2.4 调参与最终模型</h2><p><strong>调参（paraemeter tuning）</strong>：对算法的参数进行设定。</p><p><strong>验证集（validation set）</strong>：将训练数据另外划分为训练集和验证集，基于验证集上的性能进行模型参数选择和调参。</p><h1 id="2-3-性能度量"><a href="#2-3-性能度量" class="headerlink" title="2.3 性能度量"></a>2.3 性能度量</h1><p><strong>性能度量（performance measure）</strong>：衡量模型泛化能力的评价标准（相对的）。</p><p>常用的性能度量——<strong>均方误差（mean squared error）</strong>:</p><ul><li><p>离散：</p><script type="math/tex; mode=display">E(f;D) = \frac{1}{m}\sum_{i=1}^{m}{(f(x_{i})-y_{i})^2}</script></li><li><p>连续：</p><script type="math/tex; mode=display">E(f;D)=\int_{x\sim D}{(f(x)-y)^2}p(x)dx</script></li></ul><h2 id="2-3-1-错误率与精度"><a href="#2-3-1-错误率与精度" class="headerlink" title="2.3.1 错误率与精度"></a>2.3.1 错误率与精度</h2><p><strong>错误率</strong>：分类错误的样本数占样本总数的比例。</p><ul><li><p>离散：</p><script type="math/tex; mode=display">E(f;D)=\frac{1}{m}\sum_{i=1}^{m}{\amalg(f(x_i)\neq y_i)}</script></li><li><p>连续：</p><script type="math/tex; mode=display">E(f;D)=\int_{x\sim D}{\amalg(f(x)\neq y)p(x)dx}</script></li></ul><p><strong>精度</strong>：分类正确的样本数占样本总数的比例。</p><ul><li><p>离散：</p><script type="math/tex; mode=display">acc(f;D)=\frac{1}{m}\sum_{i=1}^{m}{\amalg(f(x_i)=y_i)}=1-E(f;D)</script></li><li><p>连续：</p><script type="math/tex; mode=display">acc(f;D)=\int_{x\sim D}{\amalg(f(x)=y)p(x)dx}=1-E(f;D)</script></li></ul><h2 id="2-3-2-查准率、查全率与F1"><a href="#2-3-2-查准率、查全率与F1" class="headerlink" title="2.3.2 查准率、查全率与F1"></a>2.3.2 查准率、查全率与F1</h2><ul><li><p><strong>真正例（true positive）</strong>：TP</p></li><li><p><strong>假正例（false positive）</strong>：FP</p></li><li><p><strong>真反例（true negative）</strong>：TN</p></li><li><p><strong>假反例（false negative）</strong>：FN</p></li></ul><p><strong><em>注：TP + FP + TN + FN = 样例总数</em></strong></p><p><img src="/2023/06/05/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/分类混淆矩阵.png" alt="分类混淆矩阵"></p><p><strong>查准率（precision）</strong>：在所有预测的正例中真正例的比例（“所查有多准”）。</p><script type="math/tex; mode=display">P = \frac{TP}{TP+FP}</script><p>注：分母TP+FP为预测为真的总数</p><p><strong>查全率（recall）</strong>：所有的正例中有多少被查出来了（“所查有多全”）。</p><script type="math/tex; mode=display">R = \frac{TP}{TP+FN}</script><p>注：分母TP+FN为实际为真的总数</p><p><strong>P-R曲线</strong>：查准率和查全率是两个互斥的变量，查全率高时查准率往往偏低，查准率高时查全率往往偏低。</p><p><img src="/2023/06/05/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/P-R曲线和平衡点示意图.png" alt="P-R曲线和平衡点示意图"></p><p><strong>度量学习器优劣的方法：</strong></p><ol><li><p>直接法：若一个学习器的P-R曲线被另一个学习器的曲线完全“包住”，则可以断言后者的性能优于前者</p></li><li><p>面积法：比较两个学习器P-R曲线下面积的大小，面积大的曲线性能更好</p></li><li><p>平衡点法：平衡点（BEP）是“查准率=查全率”时的取值，平衡点更大者性能更好</p></li><li><p>F1度量：</p><script type="math/tex; mode=display">F1 = \frac{2\times P\times R}{P+R}</script></li><li><p>F1度量的更一般形式 ——<script type="math/tex">F_\beta</script>度量：</p><script type="math/tex; mode=display">F_\beta=\frac{(1+\beta^2)\times P\times R}{(\beta^2\times P)+R}</script><p>注：<script type="math/tex">\beta=1</script>时退化为F1度量，<script type="math/tex">\beta>1</script>时查全率影响更大，<script type="math/tex">\beta<1</script>时查准率影响更大</p></li><li><p>宏查准率（macro-P）、宏查全率（macro-R）、宏F1（macro-F1）：先计算P、R、F1，再取平均</p></li><li><p>微查准率（micro-P）、微查全率（micro-R）、微F1（micro-F1）：先取平均，再计算P、R、F1</p><p>注：方法6和方法7性能差别不大</p></li></ol><h2 id="2-3-3-ROC和AUC"><a href="#2-3-3-ROC和AUC" class="headerlink" title="2.3.3 ROC和AUC"></a>2.3.3 ROC和AUC</h2><p>很多学习器是从测试样本产生一个实值或概率预测，然后将这个预测值与一个分类阈值（threshold）比较，若大于阈值则为正类，否则为反类。若更重视查准率，则可以选择排序中靠前的位置截断；若更重视查全率，则可以选择靠后的位置截断。因此，<strong>排序本身的质量好坏，体现了综合考虑学习器在不同任务下期望泛化性能的好坏</strong>。</p><p><strong>ROC（受试者工作特征Receiver Operating Characteristic）曲线</strong>：</p><p><img src="/2023/06/05/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/ROC曲线和AUC.png" alt="ROC曲线和AUC"></p><blockquote><p><strong>ROC曲线理解：</strong></p><p>真正例率TPR：抓住坏人的比例</p><p>假正例率FPR：误伤好人的比例</p><p>1处：好人全放走，坏人全抓到（理想情况）</p><p>2处：不论好人坏人全部抓</p><p>3处：好人全抓了，坏人全放走（最差情况）</p><p>4处：不论好人坏人全部放</p><p><strong>因此ROC曲线越接近于点（0, 1）越好，越接近对角线（随机猜测）越差。</strong></p></blockquote><p><strong>AUC（Area Under ROC Curve）</strong>：ROC曲线下的面积（学习器比较的合理判据）。</p><ul><li><p>几何法：</p><script type="math/tex; mode=display">AUC=\frac{1}{2}\sum_{i=1}^{m-1}{(x_{i+1}-x_i)(y_{i+1}+y_i)}</script></li><li><p>损失法：</p><script type="math/tex; mode=display">AUC = 1-l_{rank}</script><script type="math/tex; mode=display">l_{rank}=\frac{1}{m^+\times m^-}\sum_{x^+\in D^+}\sum_{x^-\in D^-}\Big(\amalg(f(x^+)<f(x^-))+\frac{1}{2}\amalg(f(x^+)=f(x^-))\Big)</script><p>注：<script type="math/tex">l_{rank}</script>是排序损失，对应ROC曲线之上的面积。考虑每一对正例和反例，若正例的预测值小于反例，则记1个“罚分”；若相等，则记0.5个“罚分”。</p></li></ul><h2 id="2-3-4-代价敏感错误率与代价曲线"><a href="#2-3-4-代价敏感错误率与代价曲线" class="headerlink" title="2.3.4 代价敏感错误率与代价曲线"></a>2.3.4 代价敏感错误率与代价曲线</h2><p><strong>非均等代价（unequal cost）</strong>：把第i类的样本预测为第j类的代价和把第j类的样本预测为第i类的代价不相等（<script type="math/tex">cost_{ij}\neq cost_{ji}</script>）。</p><p><img src="/2023/06/05/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/二分类代价矩阵.png" alt="二分类代价矩阵"></p><p>注：<script type="math/tex">cost_{ii}=0</script>表示分类正确的代价为0</p><p><strong>代价敏感错误率（cost-sesitive error rate）</strong>：</p><ul><li>离散：</li></ul><script type="math/tex; mode=display">E(f;D;cost)=\frac{1}{m}\Big(\sum_{x_i\in D^+}\amalg(f(x_i)\neq y_i)\times cost_{01}+\sum_{x_i\in D^-}\amalg(f(x_i)\neq y_i)\times cost_{10}\Big)</script><ul><li>连续：</li></ul><script type="math/tex; mode=display">E(f;D;cost)=cost_{01}\int_{x\sim D^+}{\amalg(f(x)\neq y)p(x)dx}+cost_{10}\int_{x\sim D^-}{\amalg(f(x)\neq y)p(x)dx}</script><p><strong>代价曲线（cost curve）</strong>：</p><p>p是样例为正例的概率，则</p><p>横轴为正例概率代价：<script type="math/tex">P(+)cost=\frac{p\times cost_{01}}{p\times cost_{01}+(1-p)\times cost_{10}}</script></p><p>纵轴为归一化代价：<script type="math/tex">cost_{norm}=\frac{FNR\times p\times cost_{01}+FPR\times (1-p)\times cost_{10}}{p\times cost_{01}+(1-p)\times cost_{10}}</script></p><p><img src="/2023/06/05/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/代价曲线和期望总体代价.png" alt="代价曲线和期望总体代价"></p><p>注：ROC曲线上的每一点对应了代价平面上的一条线段，取所有线段的下界，围成的面积即为在所有条件下学习器的期望总体代价。</p><h1 id="2-4-比较检验"><a href="#2-4-比较检验" class="headerlink" title="2.4 比较检验"></a>2.4 比较检验</h1><p><strong>统计假设检验（hypothesis test）</strong>：验证所选模型在结构上、形式上、变化方向上能否代表客观情况。若在测试集上观察到学习器A比B好，那么基于假设检验的结果我们可以推断出A的泛化能力是否在统计意义上优于B，以及这个结论的把握有多大。</p><h2 id="2-4-1-假设检验"><a href="#2-4-1-假设检验" class="headerlink" title="2.4.1 假设检验"></a>2.4.1 假设检验</h2><blockquote><p><strong>假设检验五步骤：</strong></p><p>Step1：根据实际问题要求提出原假设和备选假设</p><p>Step2：选择一个合适的检验统计量，并确定拒绝域</p><p>Step3：给定显著性水平<script type="math/tex">\alpha</script></p><p>Step4：计算在该显著性水平下、原假设成立条件下检验统计量的具体值</p><p>Step5：做出判断，若计算结果在拒绝域内则拒绝原假设，备选假设成立；否则原假设成立</p></blockquote><p><em>具体参见：<a href="https://blog.csdn.net/weixin_42468475/article/details/116240528?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522168597517916800180686762%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=168597517916800180686762&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-116240528-null-null.142^v88^insert_down38v5,239^v2^insert_chatgpt&amp;utm_term=假设检验&amp;spm=1018.2226.3001.4187">假设检验及例题讲解</a></em></p><h2 id="2-4-2-交叉验证t检验"><a href="#2-4-2-交叉验证t检验" class="headerlink" title="2.4.2 交叉验证t检验"></a>2.4.2 交叉验证t检验</h2><p><strong>k折交叉验证成对t检验（k-fold cross validation paired t-test）</strong>：对两个学习器A和B采用相同的k折交叉验证法，得到成对的测试错误率<script type="math/tex">\epsilon_1^A,\epsilon_2^A,...,\epsilon_k^A</script>和<script type="math/tex">\epsilon_1^B,\epsilon_2^B,...,\epsilon_k^B</script>，再对每对结果求差<script type="math/tex">\Delta_i=\epsilon_i^A+\epsilon_i^B</script>，最后求出差值<script type="math/tex">\Delta_1,\Delta_2,...,\Delta_k</script>的均值和方差，在显著性水平<script type="math/tex">\alpha</script>下，若变量<script type="math/tex">\tau_t=\lvert\sqrt{k}\mu/\sigma\rvert</script>小于临界值小于<script type="math/tex">t_{\alpha/2,k-1}</script>，则假设不能被拒绝，即认为两个学习器的性能相同；否则拒绝假设，即认为两个学习器的性能不同，且平均错误率较小的那个学习器性能更好。</p><p>注：通常采用<script type="math/tex">5\times 2</script>交叉验证法</p><h2 id="2-4-3-McNemar检验"><a href="#2-4-3-McNemar检验" class="headerlink" title="2.4.3 McNemar检验"></a>2.4.3 McNemar检验</h2><p><strong>列联表（contingency table）</strong>：</p><p><img src="/2023/06/05/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/两个学习器分类差别的列联表.png" alt="两个学习器分类差别的列联表"></p><p><strong>McNemar检验</strong>：考虑变量</p><script type="math/tex; mode=display">\tau_{\chi^2}=\frac{(\lvert e_{01}-e_{10}\rvert -1)^2}{e_{01}+e_{10}}</script><p>服从自由度为1的卡方分布。给定显著度<script type="math/tex">\alpha</script>，若该变量值小于临界值<script type="math/tex">\chi_{\alpha}^2</script>则不能拒绝假设，即认为两个学习器的性能相同；否则拒绝假设，即认为两个学习器的性能不同，且平均错误率较小的那个学习器性能更好。</p><h2 id="2-4-4-Friedman检验-与-Nemenyi后续检验"><a href="#2-4-4-Friedman检验-与-Nemenyi后续检验" class="headerlink" title="2.4.4 Friedman检验 与 Nemenyi后续检验"></a>2.4.4 Friedman检验 与 Nemenyi后续检验</h2><blockquote><p>当有多个算法参与比较时，一种做法是在每个数据集上分别列出两两比较的结果，而在两两比较时可以采用前述方法；另一种方法更直接，即使用基于算法排序的Friedman检验。</p></blockquote><p><strong>Friedman检验</strong>：在N个数据集上对k个算法进行比较，首先使用留出法/交叉验证法得到每个算法在每个数据集上的测试结果，然后在每个数据集上根据测试性能由好到坏进行排序并赋序值1, 2, …（若性能相同则评分序值），之后求出每个算法的平均序值。设第i个算法的平均序值为<script type="math/tex">r_i</script>，其均值和方差分别为<script type="math/tex">(k+1)/2</script>和<script type="math/tex">(k^2-1)/12N</script>，考虑变量</p><script type="math/tex; mode=display">\tau_F=\frac{(N-1)\tau_{\chi^2}}{N(k-2)-\tau_{\chi^2}}</script><script type="math/tex; mode=display">\tau_{\chi^2} = \frac{k-1}{k}\times\frac{12N}{k^2-1}\sum_{i=1}^{k}{\Big(r_i-\frac{k+1}{2}\Big)^2}=\frac{12N}{k(k+1)}{\sum_{i=1}^{k}{\Big(r_i^2}-\frac{k(k+1)^2}{4}\Big)}</script><p>服从自由度为k-1和(k-1)(N-1)的F分布。</p><blockquote><p>若“所有算法性能相同”的假设被拒绝，则说明算法的性能显著不同，这时需要进行“后续检验”（post-hoc test）来进一步区分各个算法，常用的有Nemeyi后续检验。</p></blockquote><p><strong>Nemeyi后续检验</strong>：计算出平均序值差别的临界值域</p><script type="math/tex; mode=display">CD=q_\alpha\sqrt{\frac{k(k+1)}{6N}}</script><p>若两个算法的平均序值之差超过了临界值域，则认为两个算法的性能显著不同；否则则认为两个算法的性能没有显著差别。</p><h1 id="2-5-偏差和方差"><a href="#2-5-偏差和方差" class="headerlink" title="2.5 偏差和方差"></a>2.5 偏差和方差</h1><p><strong>偏差-方差分解（bias-variance decomposition）</strong>：解释学习算法泛化性能的重要工具，试图对学习算法的期望泛化错误率进行拆解。</p><p><strong>方差（variance）</strong>：模型多次输出和平均值之间的差的期望（反映模型稳定性）</p><script type="math/tex; mode=display">var(x)=E_D\Big[(f(x;D)-\bar f(x))^2\Big]</script><p><strong>偏差（bias）</strong>：期望输出与真实标记的差别（反映模型本身拟合能力）</p><script type="math/tex; mode=display">bias^2(x)=(\bar f(x)-y)^2</script><p><strong>噪声</strong>：</p><script type="math/tex; mode=display">\epsilon^2=E_D\Big[(y_D-y)^2\Big]</script><p><strong>泛化误差</strong>：可以分解为偏差、方差与噪声之和</p><script type="math/tex; mode=display">E(f;D)=bias^2(x)+var(x)+\epsilon^2</script><p><strong>偏差-方差窘境（bias-variance dilemma）</strong>：偏差和方差是有冲突的</p><p><img src="/2023/06/05/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/泛化误差与偏差、方差的关系.png" alt="泛化误差与偏差、方差的关系"></p><p>注：训练程度低时，模型出现欠拟合；训练程度高时，模型出现过拟合。关键在于找到泛化误差曲线的最小值点，该点所对应的训练程度为最优。</p>]]></content>
      
      
      <categories>
          
          <category> ML study </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>周志华《机器学习》（AKA：西瓜书）笔记整理-第一章-绪论</title>
      <link href="/2023/06/05/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%B8%80%E7%AB%A0-%E7%BB%AA%E8%AE%BA/"/>
      <url>/2023/06/05/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%88AKA%EF%BC%9A%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86-%E7%AC%AC%E4%B8%80%E7%AB%A0-%E7%BB%AA%E8%AE%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="1-1-引言"><a href="#1-1-引言" class="headerlink" title="1.1 引言"></a>1.1 引言</h1><p><strong>机器学习</strong>：致力于研究如何通过计算的手段，利用经验（数据）来改善系统自身的性能，是研究关于在计算机上从数据中产生“模型”（model）的算法，即“学习算法”。<br><strong>模型</strong>：泛指从数据中学得的结果，一些文献中用“模型”指全局性结果，而用“模式”指局部性结果。</p><h1 id="1-2-基本术语"><a href="#1-2-基本术语" class="headerlink" title="1.2 基本术语"></a>1.2 基本术语</h1><p><strong>数据集（data set）</strong>：一组记录的集合。<br><strong>样本（sample）</strong>：关于一个事件或对象的描述（记录）。<br><strong>特征（feature）/属性（attribute）</strong>：反映事件或对象在某一方面的表现或性质。<br><strong>属性值（attribute）</strong>：属性上的取值。<br><strong>属性空间（attribute space）/样本空间（sample space）/输入空间（input space）</strong>：属性张成的空间。<br><strong>特征向量（feature vector）</strong>：属性空间中一个点对应的一个坐标向量，这里的点就是一个示例。<br><strong>标记/标签（label）</strong>：关于示例结果的信息。<br><strong>样例（example）</strong>：拥有了标记信息的示例。<br><strong>训练（training）</strong>：从数据中学得模型。<br><strong>测试（testing）</strong>：学得模型后，使用其进行预测。</p><p><strong><em>监督学习（supervised learning）：</em></strong><br>分类（classification）：预测的是离散值。<br>回归（regression）：预测的是连续值。<br><strong><em>无监督学习（unsupervised learning）：</em></strong><br>聚类（clustering）：将不同样本划分为若干簇，需注意在学习过程中我们使用的训练样本通常不拥有标记信息且不清楚所划分的簇的具体概念。</p><p><strong>泛化（generalization）能力</strong>：学得模型适用于新样本的能力。<br><strong>补充：</strong><br>经验误差（empirical error）/训练误差（training error）：模型在训练集上的误差。<br>泛化误差（generalization error）：模型在新样本集（测试集）上的误差。</p><h1 id="1-3-假设空间"><a href="#1-3-假设空间" class="headerlink" title="1.3 假设空间"></a>1.3 假设空间</h1><p><strong>归纳(induction)</strong>和<strong>演绎（deduction）</strong>是科学推理的两大基本手段，前者是从特殊到一般的“泛化”过程，后者是从一般到特殊的“特化”过程。<br>显然，“从样例中学习”是一个归纳的过程，因此亦称为“归纳学习”（inductive learning）。</p><p>我们可以把学习过程看作一个在所有假设（hypothesis）组成的空间中进行搜索的过程，搜索目标是找到与训练集匹配（fit）的假设。现实问题中，我们常常面临很大的假设空间，但学习过程是基于有限样本训练集进行的，因此可能有多个假设与训练集一致，即存在着一个与训练集一致的假设集合，我们称之为版本空间（version space）。</p><h1 id="1-4-归纳偏好"><a href="#1-4-归纳偏好" class="headerlink" title="1.4 归纳偏好"></a>1.4 归纳偏好</h1><p><strong>归纳偏好（inductive bias）</strong>：机器学习算法在学习过程中对某种类型假设的偏好，任何一个有效的机器学习算法必有其归纳偏好，算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能否取得好的性能。<br><strong>奥卡姆剃刀（Occam’s razor）原理</strong>：若有多个假设与观察一致，则选最简单的那个（简单有效原则）。<br><strong>没有免费的午餐定理（NFL定理）</strong>：<br>前提：所有问题出现的机会相同、或所有问题同等重要。<br>内容：无论学习算法a多聪明、学习算法b多笨拙，它们的期望性能相同。如果某种算法在某些方面比另一种算法更优，那就必然在其他某些方面弱于另一种算法。<br>启示：要谈论算法的相对优劣，必须要针对具体的学习问题。</p><h1 id="1-5-发展历程"><a href="#1-5-发展历程" class="headerlink" title="1.5 发展历程"></a>1.5 发展历程</h1><h1 id="1-6-应用现状"><a href="#1-6-应用现状" class="headerlink" title="1.6 应用现状"></a>1.6 应用现状</h1>]]></content>
      
      
      <categories>
          
          <category> ML study </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>个人博客的说明</title>
      <link href="/2023/06/04/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E8%AF%B4%E6%98%8E/"/>
      <url>/2023/06/04/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E8%AF%B4%E6%98%8E/</url>
      
        <content type="html"><![CDATA[<h1 id="个人博客的说明"><a href="#个人博客的说明" class="headerlink" title="个人博客的说明"></a>个人博客的说明</h1><h3 id="一些废话"><a href="#一些废话" class="headerlink" title="一些废话"></a>一些废话</h3><p>本博客由Nash Swift于公元2023年6月4日，在福州市家中创建，其主要目的是记录本人在从事人工智能相关方向的学习和工作中的点滴琐碎。如果在将来的某一天，我的博客帮助到了某位朋友，在此提前说一声不客气^_^。如果需要联系本人，请发邮件至<a href="mailto:&#55;&#48;&#x39;&#x32;&#x32;&#x32;&#50;&#53;&#x31;&#x40;&#x71;&#113;&#46;&#99;&#x6f;&#109;">&#55;&#48;&#x39;&#x32;&#x32;&#x32;&#50;&#53;&#x31;&#x40;&#x71;&#113;&#46;&#99;&#x6f;&#109;</a>，我会及时地回复。由于这是本人第一次搭建个人博客，因此仍有许多不足之处，也以此勉励自己在未来的生活中不断学习精进，不断完善自身。</p><h3 id="特别鸣谢"><a href="#特别鸣谢" class="headerlink" title="特别鸣谢"></a>特别鸣谢</h3><p>本人在此特别鸣谢我的父亲和母亲，你们对我的关心和爱让我成为了更加优秀的自己；感谢我家的泰迪狗（名：逗逗），你的可爱与陪伴温暖了我的家庭和我的心；感谢福州华伦中学2015届全体师生、感谢福州第一中学2018届全体师生、感谢中南大学机电工程学院机械设计制造及自动化专业2022届全体师生，以及在我漫漫求学之路上帮助过我的每一个人，你们见证了我过去的足迹，而我也将带着你们希冀的目光不断前行；感谢一位名为Mandy的可爱女孩，你陪伴我经历了最为宝贵的10年青春，是我最好最好最好的朋友，友谊地久天长！最后也提前感谢厦门大学信息学院人工智能研究院的各位老师，感谢smartdsp实验室的各位师生，在未来三年的研究生阶段能与诸位同行，是我极大的荣幸。<br>鄙人一介平民，才疏学浅，但却有着满腔热诚，希望未来的自己能始终坚定地走着自己的道路，不忘初心方得始终。<br>最后借用《红楼梦》中薛宝钗所作《临江仙·柳絮》中的一句话：好风凭借力，送我上青云！</p>]]></content>
      
      
      
        <tags>
            
            <tag> Hexo, Markdown </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2023/06/04/hello-world/"/>
      <url>/2023/06/04/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
